{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ecd4132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from pythainlp import word_tokenize, word_vector\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8897ee10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üü¢ Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üü¢ Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0c6f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 256\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 500\n",
    "LEARNING_RATE = 2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaf8dd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"D:\\year4\\‡∏™‡∏´‡∏Å‡∏¥‡∏à\\prachatai_train.csv\")\n",
    "texts = df[\"body_text\"].astype(str).tolist()\n",
    "label_cols = [\n",
    "    \"politics\", \"human_rights\", \"quality_of_life\", \"international\",\n",
    "    \"social\", \"environment\", \"economics\", \"culture\", \"labor\",\n",
    "    \"national_security\", \"ict\", \"education\"\n",
    "]\n",
    "y = df[label_cols].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6ea6901",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = word_vector.WordVector(model_name=\"thai2fit_wv\").get_model()\n",
    "embedding_dim = w2v.vector_size\n",
    "vocab_list = list(w2v.key_to_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e667dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "for i, word in enumerate(vocab_list, start=2):\n",
    "    vocab[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2a4f209",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = [word_tokenize(t, keep_whitespace=False) for t in texts]\n",
    "\n",
    "def encode_text(tokens, vocab):\n",
    "    return [vocab.get(w, vocab[\"<UNK>\"]) for w in tokens]\n",
    "\n",
    "encoded_texts = [encode_text(tokens, vocab) for tokens in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f32bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, max_len=256, pad_value=0):\n",
    "    padded = np.full((len(sequences), max_len), pad_value, dtype=np.int64)\n",
    "    lengths = np.array([min(len(seq), max_len) for seq in sequences], dtype=np.int64) # ‡∏Å‡∏±‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô\n",
    "    for i, seq in enumerate(sequences):\n",
    "        end = min(len(seq), max_len)\n",
    "        padded[i, :end] = seq[:end]\n",
    "    return padded, lengths\n",
    "\n",
    "X, lengths = pad_sequences(encoded_texts, max_len=MAX_LEN)\n",
    "\n",
    "# First split: 80% train, 20% temp\n",
    "X_train, X_temp, y_train, y_temp, len_train, len_temp = train_test_split(\n",
    "    X, y, lengths, test_size=0.2, random_state=42\n",
    ")\n",
    "# Second split: 50% test, 50% valid (from temp = 10% each of total)\n",
    "X_test, X_val, y_test, y_val, len_test, len_val = train_test_split(\n",
    "    X_temp, y_temp, len_temp, test_size=0.5, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a0f9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThaiTextDataset(Dataset):\n",
    "    def __init__(self, X, lengths, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.long)\n",
    "        self.lengths = torch.tensor(lengths, dtype=torch.long)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "    def __len__(self): return len(self.y)\n",
    "    def __getitem__(self, idx): return self.X[idx], self.lengths[idx], self.y[idx]\n",
    "\n",
    "train_loader = DataLoader(ThaiTextDataset(X_train, len_train, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(ThaiTextDataset(X_test, len_test, y_test), batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(ThaiTextDataset(X_val, len_val, y_val), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8486847",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, idx in vocab.items():\n",
    "    if word in w2v:\n",
    "        embedding_matrix[idx] = w2v[word]\n",
    "    else:\n",
    "        embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8480f4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, max_seq_len, output_dim, depth=4, heads=4, embedding_matrix=None):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        # 1. Embedding\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        if embedding_matrix is not None:\n",
    "            self.embedding.weight.data.copy_(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "            self.embedding.weight.requires_grad = True # Fine-tune embedding ‡∏î‡πâ‡∏ß‡∏¢\n",
    "            \n",
    "        # 2. Positional Encoding (‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Standard Transformer)\n",
    "        self.pos_encoder = nn.Parameter(torch.randn(1, max_seq_len, embed_dim))\n",
    "        \n",
    "        # 3. Transformer Encoder (Native PyTorch = Fast)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, \n",
    "            nhead=heads, \n",
    "            dim_feedforward=embed_dim * 4,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=depth)\n",
    "        \n",
    "        # 4. Output\n",
    "        self.fc = nn.Linear(embed_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # Create Padding Mask (Batch, Seq_Len) -> True where padding\n",
    "        src_key_padding_mask = (x == 0)\n",
    "\n",
    "        # Embed + Pos Encode\n",
    "        x = self.embedding(x) * math.sqrt(self.embed_dim)\n",
    "        x = x + self.pos_encoder[:, :x.size(1), :]\n",
    "        \n",
    "        # Transformer Pass\n",
    "        x = self.transformer_encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
    "        \n",
    "        # Mean Pooling (Ignore padding in calculation if possible, but basic mean is usually ok)\n",
    "        x = x.mean(dim=1) \n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74fc096",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerClassifier(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=embedding_dim,\n",
    "    max_seq_len=MAX_LEN,\n",
    "    output_dim=len(label_cols),\n",
    "    depth=4,     # ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏•‡∏∂‡∏Å‡∏°‡∏≤‡∏Å ‡∏Ç‡πà‡∏≤‡∏ß‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Ç‡∏ô‡∏≤‡∏î‡∏ô‡∏±‡πâ‡∏ô\n",
    "    heads=4,     # 300 ‡∏´‡∏≤‡∏£ 6 ‡∏•‡∏á‡∏ï‡∏±‡∏ß‡∏û‡∏≠‡∏î‡∏µ\n",
    "    embedding_matrix=embedding_matrix\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe753a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nawapol\\anaconda3\\envs\\PT\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Start Training... (Max Epochs: 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nawapol\\anaconda3\\envs\\PT\\Lib\\site-packages\\torch\\nn\\functional.py:5476: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 | Loss: 0.2649 | LR: 0.000100 | Time: 93.7s\n",
      "Epoch 2/500 | Loss: 0.1904 | LR: 0.000100 | Time: 95.8s\n",
      "Epoch 3/500 | Loss: 0.1680 | LR: 0.000100 | Time: 97.0s\n",
      "Epoch 4/500 | Loss: 0.1490 | LR: 0.000100 | Time: 97.3s\n",
      "Epoch 5/500 | Loss: 0.1299 | LR: 0.000100 | Time: 96.8s\n",
      "Epoch 6/500 | Loss: 0.1119 | LR: 0.000100 | Time: 98.1s\n",
      "Epoch 7/500 | Loss: 0.0950 | LR: 0.000100 | Time: 98.2s\n",
      "Epoch 8/500 | Loss: 0.0807 | LR: 0.000100 | Time: 98.4s\n",
      "Epoch 9/500 | Loss: 0.0671 | LR: 0.000100 | Time: 98.7s\n",
      "Epoch 10/500 | Loss: 0.0561 | LR: 0.000100 | Time: 98.4s\n",
      "Epoch 11/500 | Loss: 0.0470 | LR: 0.000100 | Time: 98.3s\n",
      "Epoch 12/500 | Loss: 0.0393 | LR: 0.000100 | Time: 102.2s\n",
      "Epoch 13/500 | Loss: 0.0334 | LR: 0.000100 | Time: 98.6s\n",
      "Epoch 14/500 | Loss: 0.0287 | LR: 0.000100 | Time: 114.4s\n",
      "Epoch 15/500 | Loss: 0.0248 | LR: 0.000100 | Time: 113.3s\n",
      "Epoch 16/500 | Loss: 0.0222 | LR: 0.000100 | Time: 113.8s\n",
      "Epoch 17/500 | Loss: 0.0200 | LR: 0.000100 | Time: 121.1s\n",
      "Epoch 18/500 | Loss: 0.0179 | LR: 0.000100 | Time: 119.8s\n",
      "Epoch 19/500 | Loss: 0.0167 | LR: 0.000100 | Time: 97.6s\n",
      "Epoch 20/500 | Loss: 0.0156 | LR: 0.000100 | Time: 96.8s\n",
      "Epoch 21/500 | Loss: 0.0139 | LR: 0.000100 | Time: 97.3s\n",
      "Epoch 22/500 | Loss: 0.0138 | LR: 0.000100 | Time: 97.2s\n",
      "Epoch 23/500 | Loss: 0.0128 | LR: 0.000100 | Time: 98.8s\n",
      "Epoch 24/500 | Loss: 0.0124 | LR: 0.000100 | Time: 97.5s\n",
      "Epoch 25/500 | Loss: 0.0120 | LR: 0.000100 | Time: 97.6s\n",
      "Epoch 26/500 | Loss: 0.0111 | LR: 0.000100 | Time: 96.9s\n",
      "Epoch 27/500 | Loss: 0.0108 | LR: 0.000100 | Time: 96.9s\n",
      "Epoch 28/500 | Loss: 0.0100 | LR: 0.000100 | Time: 98.0s\n",
      "Epoch 29/500 | Loss: 0.0101 | LR: 0.000100 | Time: 97.4s\n",
      "Epoch 30/500 | Loss: 0.0100 | LR: 0.000100 | Time: 99.4s\n",
      "Epoch 31/500 | Loss: 0.0094 | LR: 0.000100 | Time: 97.1s\n",
      "Epoch 32/500 | Loss: 0.0087 | LR: 0.000100 | Time: 96.5s\n",
      "Epoch 33/500 | Loss: 0.0081 | LR: 0.000100 | Time: 96.5s\n",
      "Epoch 34/500 | Loss: 0.0083 | LR: 0.000100 | Time: 96.4s\n",
      "Epoch 35/500 | Loss: 0.0083 | LR: 0.000100 | Time: 96.4s\n",
      "Epoch 36/500 | Loss: 0.0082 | LR: 0.000100 | Time: 97.0s\n",
      "Epoch 37/500 | Loss: 0.0078 | LR: 0.000100 | Time: 96.8s\n",
      "Epoch 38/500 | Loss: 0.0077 | LR: 0.000100 | Time: 96.5s\n",
      "Epoch 39/500 | Loss: 0.0075 | LR: 0.000100 | Time: 96.3s\n",
      "Epoch 40/500 | Loss: 0.0075 | LR: 0.000100 | Time: 96.2s\n",
      "Epoch 41/500 | Loss: 0.0076 | LR: 0.000100 | Time: 96.4s\n",
      "Epoch 42/500 | Loss: 0.0070 | LR: 0.000100 | Time: 97.2s\n",
      "Epoch 43/500 | Loss: 0.0068 | LR: 0.000100 | Time: 97.3s\n",
      "Epoch 44/500 | Loss: 0.0067 | LR: 0.000100 | Time: 96.7s\n",
      "Epoch 45/500 | Loss: 0.0069 | LR: 0.000100 | Time: 96.3s\n",
      "Epoch 46/500 | Loss: 0.0061 | LR: 0.000100 | Time: 97.3s\n",
      "Epoch 47/500 | Loss: 0.0067 | LR: 0.000100 | Time: 96.8s\n",
      "Epoch 48/500 | Loss: 0.0063 | LR: 0.000100 | Time: 96.4s\n",
      "Epoch 49/500 | Loss: 0.0063 | LR: 0.000100 | Time: 96.4s\n",
      "Epoch 50/500 | Loss: 0.0057 | LR: 0.000100 | Time: 96.3s\n",
      "Epoch 51/500 | Loss: 0.0054 | LR: 0.000100 | Time: 96.3s\n",
      "Epoch 52/500 | Loss: 0.0058 | LR: 0.000100 | Time: 96.2s\n",
      "Epoch 53/500 | Loss: 0.0056 | LR: 0.000100 | Time: 96.4s\n",
      "Epoch 54/500 | Loss: 0.0058 | LR: 0.000100 | Time: 96.3s\n",
      "Epoch 55/500 | Loss: 0.0055 | LR: 0.000050 | Time: 96.3s\n",
      "Epoch 56/500 | Loss: 0.0033 | LR: 0.000050 | Time: 96.3s\n",
      "Epoch 57/500 | Loss: 0.0021 | LR: 0.000050 | Time: 96.4s\n",
      "Epoch 58/500 | Loss: 0.0017 | LR: 0.000050 | Time: 96.3s\n",
      "Epoch 59/500 | Loss: 0.0016 | LR: 0.000050 | Time: 96.3s\n",
      "Epoch 60/500 | Loss: 0.0016 | LR: 0.000050 | Time: 96.2s\n",
      "Epoch 61/500 | Loss: 0.0017 | LR: 0.000050 | Time: 96.2s\n",
      "Epoch 62/500 | Loss: 0.0017 | LR: 0.000050 | Time: 96.2s\n",
      "Epoch 63/500 | Loss: 0.0017 | LR: 0.000025 | Time: 96.2s\n",
      "Epoch 64/500 | Loss: 0.0014 | LR: 0.000025 | Time: 96.2s\n",
      "Epoch 65/500 | Loss: 0.0012 | LR: 0.000025 | Time: 96.2s\n",
      "Epoch 66/500 | Loss: 0.0010 | LR: 0.000025 | Time: 96.2s\n",
      "Epoch 67/500 | Loss: 0.0010 | LR: 0.000025 | Time: 96.2s\n",
      "Epoch 68/500 | Loss: 0.0010 | LR: 0.000025 | Time: 96.2s\n",
      "Epoch 69/500 | Loss: 0.0010 | LR: 0.000025 | Time: 96.2s\n",
      "Epoch 70/500 | Loss: 0.0010 | LR: 0.000025 | Time: 96.9s\n",
      "Epoch 71/500 | Loss: 0.0010 | LR: 0.000025 | Time: 96.6s\n",
      "Epoch 72/500 | Loss: 0.0009 | LR: 0.000025 | Time: 99.3s\n",
      "Epoch 73/500 | Loss: 0.0009 | LR: 0.000025 | Time: 96.8s\n",
      "Epoch 74/500 | Loss: 0.0009 | LR: 0.000025 | Time: 96.4s\n",
      "Epoch 75/500 | Loss: 0.0010 | LR: 0.000025 | Time: 96.3s\n",
      "Epoch 76/500 | Loss: 0.0009 | LR: 0.000025 | Time: 96.3s\n",
      "Epoch 77/500 | Loss: 0.0009 | LR: 0.000025 | Time: 96.2s\n",
      "Epoch 78/500 | Loss: 0.0009 | LR: 0.000013 | Time: 96.4s\n",
      "Epoch 79/500 | Loss: 0.0007 | LR: 0.000013 | Time: 98.2s\n",
      "Epoch 80/500 | Loss: 0.0007 | LR: 0.000013 | Time: 98.4s\n",
      "Epoch 81/500 | Loss: 0.0007 | LR: 0.000013 | Time: 97.7s\n",
      "Epoch 82/500 | Loss: 0.0006 | LR: 0.000013 | Time: 96.7s\n",
      "Epoch 83/500 | Loss: 0.0007 | LR: 0.000013 | Time: 96.3s\n",
      "Epoch 84/500 | Loss: 0.0006 | LR: 0.000013 | Time: 96.7s\n",
      "Epoch 85/500 | Loss: 0.0006 | LR: 0.000013 | Time: 96.5s\n",
      "Epoch 86/500 | Loss: 0.0007 | LR: 0.000013 | Time: 96.2s\n",
      "Epoch 87/500 | Loss: 0.0006 | LR: 0.000013 | Time: 96.3s\n",
      "Epoch 88/500 | Loss: 0.0006 | LR: 0.000013 | Time: 96.2s\n",
      "Epoch 89/500 | Loss: 0.0006 | LR: 0.000013 | Time: 96.1s\n",
      "Epoch 90/500 | Loss: 0.0006 | LR: 0.000013 | Time: 96.2s\n",
      "Epoch 91/500 | Loss: 0.0006 | LR: 0.000006 | Time: 96.3s\n",
      "Epoch 92/500 | Loss: 0.0006 | LR: 0.000006 | Time: 96.4s\n",
      "Epoch 93/500 | Loss: 0.0006 | LR: 0.000006 | Time: 96.6s\n",
      "Epoch 94/500 | Loss: 0.0005 | LR: 0.000006 | Time: 96.5s\n",
      "Epoch 95/500 | Loss: 0.0005 | LR: 0.000006 | Time: 96.4s\n",
      "Epoch 96/500 | Loss: 0.0005 | LR: 0.000006 | Time: 98.4s\n",
      "Epoch 97/500 | Loss: 0.0005 | LR: 0.000006 | Time: 98.1s\n",
      "Epoch 98/500 | Loss: 0.0005 | LR: 0.000006 | Time: 96.4s\n",
      "Epoch 99/500 | Loss: 0.0005 | LR: 0.000006 | Time: 96.3s\n",
      "Epoch 100/500 | Loss: 0.0005 | LR: 0.000006 | Time: 96.7s\n",
      "Epoch 101/500 | Loss: 0.0005 | LR: 0.000006 | Time: 96.4s\n",
      "Epoch 102/500 | Loss: 0.0005 | LR: 0.000003 | Time: 96.0s\n",
      "Epoch 103/500 | Loss: 0.0005 | LR: 0.000003 | Time: 96.0s\n",
      "Epoch 104/500 | Loss: 0.0005 | LR: 0.000003 | Time: 96.2s\n",
      "Epoch 105/500 | Loss: 0.0005 | LR: 0.000003 | Time: 95.8s\n",
      "Epoch 106/500 | Loss: 0.0005 | LR: 0.000003 | Time: 95.9s\n",
      "Epoch 107/500 | Loss: 0.0005 | LR: 0.000003 | Time: 95.9s\n",
      "Epoch 108/500 | Loss: 0.0005 | LR: 0.000003 | Time: 96.0s\n",
      "Epoch 109/500 | Loss: 0.0005 | LR: 0.000003 | Time: 96.3s\n",
      "Epoch 110/500 | Loss: 0.0005 | LR: 0.000003 | Time: 96.3s\n",
      "Epoch 111/500 | Loss: 0.0005 | LR: 0.000003 | Time: 97.2s\n",
      "Epoch 112/500 | Loss: 0.0005 | LR: 0.000003 | Time: 97.7s\n",
      "Epoch 113/500 | Loss: 0.0005 | LR: 0.000003 | Time: 97.9s\n",
      "Epoch 114/500 | Loss: 0.0005 | LR: 0.000003 | Time: 97.8s\n",
      "Epoch 115/500 | Loss: 0.0005 | LR: 0.000003 | Time: 97.9s\n",
      "Epoch 116/500 | Loss: 0.0005 | LR: 0.000003 | Time: 98.0s\n",
      "Epoch 117/500 | Loss: 0.0005 | LR: 0.000003 | Time: 97.8s\n",
      "Epoch 118/500 | Loss: 0.0005 | LR: 0.000003 | Time: 97.8s\n",
      "Epoch 119/500 | Loss: 0.0005 | LR: 0.000003 | Time: 97.7s\n",
      "Epoch 120/500 | Loss: 0.0004 | LR: 0.000003 | Time: 97.9s\n",
      "Epoch 121/500 | Loss: 0.0005 | LR: 0.000003 | Time: 97.8s\n",
      "Epoch 122/500 | Loss: 0.0005 | LR: 0.000003 | Time: 97.7s\n",
      "Epoch 123/500 | Loss: 0.0005 | LR: 0.000003 | Time: 97.8s\n",
      "Epoch 124/500 | Loss: 0.0005 | LR: 0.000002 | Time: 97.8s\n",
      "Epoch 125/500 | Loss: 0.0005 | LR: 0.000002 | Time: 97.2s\n",
      "Epoch 126/500 | Loss: 0.0005 | LR: 0.000002 | Time: 96.3s\n",
      "Epoch 127/500 | Loss: 0.0005 | LR: 0.000002 | Time: 95.9s\n",
      "Epoch 128/500 | Loss: 0.0005 | LR: 0.000001 | Time: 96.7s\n",
      "Epoch 129/500 | Loss: 0.0005 | LR: 0.000001 | Time: 96.1s\n",
      "Epoch 130/500 | Loss: 0.0005 | LR: 0.000001 | Time: 96.3s\n",
      "üõë Early stopping triggered at epoch 130\n",
      "‚úÖ Training Complete!\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5)\n",
    "scaler = GradScaler()\n",
    "\n",
    "print(f\"üöÄ Start Training... (Max Epochs: {EPOCHS})\")\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for X_batch, lengths_batch, y_batch in train_loader:\n",
    "        X_batch, lengths_batch, y_batch = X_batch.to(device), lengths_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast(): # Mixed Precision\n",
    "            outputs = model(X_batch, lengths_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    val_time = time.time() - start_time\n",
    "    \n",
    "    # Scheduler Update\n",
    "    scheduler.step(avg_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {avg_loss:.4f} | LR: {current_lr:.6f} | Time: {val_time:.1f}s\")\n",
    "\n",
    "print(\"‚úÖ Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15bec2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nawapol\\anaconda3\\envs\\PT\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:384: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\NestedTensorImpl.cpp:179.)\n",
      "  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ F1-Macro: 0.6202\n",
      "üèÜ F1-Micro: 0.6980\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model_thai2vec_transformer.pth'))\n",
    "model.eval()\n",
    "\n",
    "# F1 Score\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for X_batch, lengths_batch, y_batch in test_loader:\n",
    "        X_batch, lengths_batch = X_batch.to(device), lengths_batch.to(device)\n",
    "        outputs = model(X_batch, lengths_batch)\n",
    "        preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "        preds = (preds > 0.5).astype(int)\n",
    "        y_true.append(y_batch.numpy())\n",
    "        y_pred.append(preds)\n",
    "\n",
    "y_true = np.vstack(y_true)\n",
    "y_pred = np.vstack(y_pred)\n",
    "\n",
    "print(f\"\\nüèÜ F1-Macro: {f1_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "print(f\"üèÜ F1-Micro: {f1_score(y_true, y_pred, average='micro'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1720e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÆ Prediction Test:\n",
      "[('education', 0.6122887134552002)]\n"
     ]
    }
   ],
   "source": [
    "def predict(text):\n",
    "    model.eval()\n",
    "    tokens = word_tokenize(text, keep_whitespace=False)\n",
    "    ids = [vocab.get(w, vocab[\"<UNK>\"]) for w in tokens]\n",
    "    \n",
    "    # Handle Length\n",
    "    if len(ids) > MAX_LEN: ids = ids[:MAX_LEN]\n",
    "    else: ids = ids + [0] * (MAX_LEN - len(ids))\n",
    "    \n",
    "    tensor_in = torch.tensor([ids], dtype=torch.long).to(device)\n",
    "    len_in = torch.tensor([min(len(tokens), MAX_LEN)], dtype=torch.long).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(tensor_in, len_in)\n",
    "        probs = torch.sigmoid(output).cpu().numpy()[0]\n",
    "    \n",
    "    results = []\n",
    "    for i, prob in enumerate(probs):\n",
    "        if prob > 0.5:\n",
    "            results.append((label_cols[i], float(prob)))\n",
    "            \n",
    "    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏±‡∏ô‡πÑ‡∏´‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô 0.5 ‡πÄ‡∏•‡∏¢ ‡πÉ‡∏´‡πâ‡πÄ‡∏≠‡∏≤‡∏≠‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏°‡∏≤‡∏≠‡∏±‡∏ô‡∏ô‡∏∂‡∏á\n",
    "    if not results:\n",
    "        best_idx = np.argmax(probs)\n",
    "        results.append((label_cols[best_idx], float(probs[best_idx])))\n",
    "        \n",
    "    return results\n",
    "\n",
    "# Test Predict\n",
    "print(\"\\nüîÆ Prediction Test:\")\n",
    "print(predict(\"‡∏£‡∏±‡∏ê‡∏ö‡∏≤‡∏•‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÉ‡∏´‡∏°‡πà ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏¢‡∏≤‡∏ß‡∏ä‡∏ô\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92233969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded Best Model successfully.\n",
      "\n",
      "üìÇ Loading Test File: D:\\year4\\‡∏™‡∏´‡∏Å‡∏¥‡∏à\\prachatai_test.csv ...\n",
      "\n",
      "===================================\n",
      "üèÜ FINAL TEST RESULTS (prachatai_test)\n",
      "===================================\n",
      "Macro F1-Score: 0.6195\n",
      "Micro F1-Score: 0.6914\n",
      "-----------------------------------\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "         politics       0.79      0.85      0.82      3842\n",
      "     human_rights       0.66      0.60      0.63      1511\n",
      "  quality_of_life       0.64      0.59      0.61      1127\n",
      "    international       0.73      0.75      0.74       834\n",
      "           social       0.41      0.29      0.34       789\n",
      "      environment       0.79      0.79      0.79       772\n",
      "        economics       0.60      0.52      0.56       519\n",
      "          culture       0.56      0.48      0.52       398\n",
      "            labor       0.79      0.75      0.77       350\n",
      "national_security       0.55      0.49      0.52       338\n",
      "              ict       0.68      0.65      0.66       292\n",
      "        education       0.53      0.42      0.47       255\n",
      "\n",
      "        micro avg       0.70      0.68      0.69     11027\n",
      "        macro avg       0.64      0.60      0.62     11027\n",
      "     weighted avg       0.69      0.68      0.68     11027\n",
      "      samples avg       0.72      0.71      0.69     11027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model.load_state_dict(torch.load('best_model_thai2vec_transformer.pth'))\n",
    "    print(\"‚úÖ Loaded Best Model successfully.\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Warning: Could not load best model. Using current model state.\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# B. ‡∏ß‡∏±‡∏î‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏à‡∏£‡∏¥‡∏á (prachatai_test.csv)\n",
    "# ---------------------------------------------------------\n",
    "TEST_FILE_PATH = r\"D:\\year4\\‡∏™‡∏´‡∏Å‡∏¥‡∏à\\prachatai_test.csv\"  # üëà ‡πÅ‡∏Å‡πâ Path ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ\n",
    "\n",
    "try:\n",
    "    print(f\"\\nüìÇ Loading Test File: {TEST_FILE_PATH} ...\")\n",
    "    df_test = pd.read_csv(TEST_FILE_PATH)\n",
    "    \n",
    "    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "    test_texts = df_test[\"body_text\"].astype(str).tolist()\n",
    "    y_test_real = df_test[label_cols].values.astype(np.float32)\n",
    "\n",
    "    # Tokenize & Encode\n",
    "    tokenized_test = [word_tokenize(t, keep_whitespace=False) for t in test_texts]\n",
    "    encoded_test = [encode_text(tokens, vocab) for tokens in tokenized_test]\n",
    "    X_test_real, len_test_real = pad_sequences(encoded_test, max_len=MAX_LEN)\n",
    "\n",
    "    # DataLoader\n",
    "    real_test_loader = DataLoader(\n",
    "        ThaiTextDataset(X_test_real, len_test_real, y_test_real), \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Prediction Loop\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, lengths_batch, y_batch in real_test_loader:\n",
    "            X_batch, lengths_batch = X_batch.to(device), lengths_batch.to(device)\n",
    "            outputs = model(X_batch, lengths_batch)\n",
    "            preds = (torch.sigmoid(outputs).cpu().numpy() > 0.5).astype(int)\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(y_batch.numpy())\n",
    "\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "\n",
    "    # Report\n",
    "    print(\"\\n\" + \"=\"*35)\n",
    "    print(\"üèÜ FINAL TEST RESULTS (prachatai_test)\")\n",
    "    print(\"=\"*35)\n",
    "    print(f\"Macro F1-Score: {f1_score(all_labels, all_preds, average='macro'):.4f}\")\n",
    "    print(f\"Micro F1-Score: {f1_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "    print(\"-\" * 35)\n",
    "    print(classification_report(all_labels, all_preds, target_names=label_cols, zero_division=0))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Skipped Test File Evaluation: {e}\")\n",
    "    print(\"(‡∏≠‡∏≤‡∏à‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠ Column ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á)\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# C. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏•‡∏≠‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏•‡πà‡∏ô‡πÄ‡∏≠‡∏á (Manual Predict)\n",
    "# ---------------------------------------------------------\n",
    "def predict(text, show_all=True, threshold=0.5):\n",
    "    \"\"\"\n",
    "    show_all: ‡∏ñ‡πâ‡∏≤ True ‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ó‡∏∏‡∏Å‡∏´‡∏°‡∏ß‡∏î (‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏°‡∏≤‡∏Å‡πÑ‡∏õ‡∏ô‡πâ‡∏≠‡∏¢)\n",
    "              ‡∏ñ‡πâ‡∏≤ False ‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏´‡∏°‡∏ß‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏ô threshold\n",
    "    threshold: ‡∏Ñ‡πà‡∏≤‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏°‡∏ß‡∏î‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á (default = 0.5)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    tokens = word_tokenize(text, keep_whitespace=False)\n",
    "    ids = [vocab.get(w, vocab[\"<UNK>\"]) for w in tokens]\n",
    "    \n",
    "    if len(ids) > MAX_LEN: ids = ids[:MAX_LEN]\n",
    "    else: ids = ids + [0] * (MAX_LEN - len(ids))\n",
    "    \n",
    "    tensor_in = torch.tensor([ids], dtype=torch.long).to(device)\n",
    "    len_in = torch.tensor([min(len(tokens), MAX_LEN)], dtype=torch.long).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(tensor_in, len_in)\n",
    "        probs = torch.sigmoid(output).cpu().numpy()[0]\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á list ‡∏Ñ‡∏π‡πà (‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏°‡∏ß‡∏î, ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô) ‡∏ó‡∏∏‡∏Å‡∏´‡∏°‡∏ß‡∏î\n",
    "    all_results = [(label_cols[i], float(prob)) for i, prob in enumerate(probs)]\n",
    "    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏°‡∏≤‡∏Å‡πÑ‡∏õ‡∏ô‡πâ‡∏≠‡∏¢\n",
    "    all_results.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    if show_all:\n",
    "        return all_results\n",
    "    else:\n",
    "        # ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏´‡∏°‡∏ß‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏ô threshold\n",
    "        filtered = [(name, prob) for name, prob in all_results if prob > threshold]\n",
    "        if not filtered:\n",
    "            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏•‡∏¢ ‡πÄ‡∏≠‡∏≤‡∏≠‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏°‡∏≤‡∏≠‡∏±‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß\n",
    "            filtered = [all_results[0]]\n",
    "        return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d0c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÆ Manual Prediction Test:\n",
      "Input: ‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡πÑ‡∏ó - ‡∏°‡∏ï‡∏¥‡∏û‡∏±‡∏ô‡∏ò‡∏°‡∏¥‡∏ï‡∏£‡∏Ø ‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ‡πÄ‡∏î‡∏¥‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏±‡∏î‡πÄ‡∏ß‡∏ó‡∏µ‡∏õ‡∏è‡∏¥‡∏£‡∏π‡∏õ‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á 29 - 30 ‡πÄ‡∏°‡∏©‡∏≤‡∏Ø ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏•‡∏∏‡∏¢‡∏ü‡πâ‡∏≠‡∏á‡∏®‡∏≤‡∏•‡∏õ‡∏Å‡∏Ñ‡∏£‡∏≠‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏¥‡∏Å‡∏ñ‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á 23 ‡πÄ‡∏°‡∏©‡∏≤‡∏Ø ‡∏ó‡∏ô‡∏≤‡∏¢‡∏ä‡∏µ‡πâ‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏≠‡∏∑‡πâ‡∏≠‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡πÉ‡∏´‡πâ‡πÑ‡∏ó‡∏¢‡∏£‡∏±‡∏Å‡πÑ‡∏ó‡∏¢‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏ß‡∏•‡∏≤ 10.30 ‡∏ô. ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 9 ‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô 2549 ‡∏ó‡∏µ‡πà‡∏´‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏Ñ‡∏ì‡∏∞‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ ‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡∏™‡∏á‡∏Ç‡∏•‡∏≤‡∏ô‡∏Ñ‡∏£‡∏¥‡∏ô‡∏ó‡∏£‡πå ‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡πÄ‡∏Ç‡∏ï‡∏´‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡πÅ‡∏Å‡∏ô‡∏ô‡∏≥‡∏û‡∏±‡∏ô‡∏ò‡∏°‡∏¥‡∏ï‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ò‡∏¥‡∏õ‡πÑ‡∏ï‡∏¢ ‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ ‡∏°‡∏µ‡∏ú‡∏π‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏° 30 ‡∏Ñ‡∏ô ‡πÇ‡∏î‡∏¢‡πÑ‡∏î‡πâ‡πÄ‡∏ä‡∏¥‡∏ç‡∏ô‡∏≤‡∏¢‡∏õ‡∏Å‡∏£‡∏ì‡πå ‡∏£‡∏≠‡∏á‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏¥‡πå ‡∏õ‡∏£‡∏∞‡∏ò‡∏≤‡∏ô‡∏™‡∏†‡∏≤‡∏ó‡∏ô‡∏≤‡∏¢‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏™‡∏á‡∏Ç‡∏•‡∏≤ ‡∏°‡∏≤‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏≤‡∏á‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á ‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 23 ‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô 2549‡∏ô‡∏≤‡∏¢‡∏õ‡∏Å‡∏£‡∏ì‡πå ‡∏Å‡∏•‡πà‡∏≤‡∏ß‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡∏ß‡πà‡∏≤ ‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ì‡∏∞‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á (‡∏Å‡∏Å‡∏ï.) ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏£‡∏±‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏™‡∏†‡∏≤‡∏ú‡∏π‡πâ‡πÅ‡∏ó‡∏ô‡∏£‡∏≤‡∏©‡∏é‡∏£‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 2 ‡πÉ‡∏ô‡πÄ‡∏Ç‡∏ï‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡πÑ‡∏î‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÑ‡∏°‡πà‡∏ñ‡∏∂‡∏á‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ 20 ‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏≠‡∏∑‡πâ‡∏≠‡πÉ‡∏´‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏£‡∏£‡∏Ñ‡πÑ‡∏ó‡∏¢‡∏£‡∏±‡∏Å‡πÑ‡∏ó‡∏¢ ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ú‡∏¥‡∏î‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏£‡∏±‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏£‡∏±‡∏ö‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏£‡∏±‡∏ê‡∏ò‡∏£‡∏£‡∏°‡∏ô‡∏π‡∏ç‡∏ß‡πà‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏™‡∏†‡∏≤‡∏ú‡∏π‡πâ‡πÅ‡∏ó‡∏ô‡∏£‡∏≤‡∏©‡∏é‡∏£‡πÅ‡∏•‡∏∞‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏ß‡∏∏‡∏í‡∏¥‡∏™‡∏†‡∏≤ ‡∏°‡∏≤‡∏ï‡∏£‡∏≤ 74(2) ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏´‡∏°‡πà ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏£‡∏±‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏´‡∏°‡πà ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á‡∏Å‡πá‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏û‡∏£‡∏£‡∏Ñ‡πÑ‡∏ó‡∏¢‡∏£‡∏±‡∏Å‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç 2 ‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å‡∏à‡∏∂‡∏á‡πÑ‡∏î‡πâ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÑ‡∏î‡πâ‡∏´‡∏≤‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡∏ô‡∏≤‡∏¢‡∏õ‡∏Å‡∏£‡∏ì‡πå ‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏≠‡∏µ‡∏Å‡∏ß‡πà‡∏≤ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô ‡∏ï‡∏≤‡∏°‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏ö‡∏±‡∏ç‡∏ç‡∏±‡∏ï‡∏¥‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏£‡∏±‡∏ê‡∏ò‡∏£‡∏£‡∏°‡∏ô‡∏π‡∏ç‡∏ß‡πà‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ì‡∏∞‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á ‡∏°‡∏≤‡∏ï‡∏£‡∏≤ 24 ‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤ ‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏¥‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á ‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏ô‡πÄ‡∏Ç‡∏ï‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á ‡πÅ‡∏•‡∏∞‡∏≠‡∏ô‡∏∏‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á ‡∏Å‡∏£‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏ô‡∏°‡∏¥‡∏ä‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏´‡πâ‡πÇ‡∏ó‡∏©‡πÅ‡∏Å‡πà‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏£‡∏£‡∏Ñ‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á ‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏´‡∏£‡∏∑‡∏≠‡∏•‡∏∞‡πÄ‡∏ß‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡πÇ‡∏î‡∏¢‡∏°‡∏¥‡∏ä‡∏≠‡∏ö ‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡∏á‡πÇ‡∏ó‡∏©‡∏ô‡∏±‡πâ‡∏ô‡∏ï‡∏≤‡∏°‡∏°‡∏≤‡∏ï‡∏£‡∏≤ 29 ‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤ ‡πÉ‡∏´‡πâ‡∏à‡∏≥‡∏Ñ‡∏∏‡∏Å 1 -10 ‡∏õ‡∏µ ‡∏õ‡∏£‡∏±‡∏ö 20,000 - 200,000 ‡∏ö‡∏≤‡∏ó ‡πÅ‡∏•‡∏∞‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏®‡∏≤‡∏•‡πÄ‡∏û‡∏¥‡∏Å‡∏ñ‡∏≠‡∏ô‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏•‡∏≤ 10 ‡∏õ‡∏µ ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡∏à‡∏∂‡∏á‡∏•‡∏á‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏ü‡πâ‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Ñ‡∏î‡∏µ‡∏õ‡∏Å‡∏Ñ‡∏£‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ì‡∏∞‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á ‡πÇ‡∏î‡∏¢‡∏à‡∏∞‡∏ü‡πâ‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡∏ï‡πà‡∏≠‡∏®‡∏≤‡∏•‡∏õ‡∏Å‡∏Ñ‡∏£‡∏≠‡∏á‡∏™‡∏á‡∏Ç‡∏•‡∏≤ ‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏®‡∏≤‡∏•‡∏õ‡∏Å‡∏Ñ‡∏£‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÄ‡∏û‡∏¥‡∏Å‡∏ñ‡∏≠‡∏ô‡∏°‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ì‡∏∞‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡∏¥‡∏î‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏£‡∏±‡∏ö‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 23 ‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô 2549 ‡πÅ‡∏•‡∏∞‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏¢‡∏±‡∏ö‡∏¢‡∏±‡πâ‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏î‡∏±‡∏á‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏î‡πâ‡∏ß‡∏¢‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡∏¢‡∏±‡∏á‡∏°‡∏µ‡∏°‡∏ï‡∏¥‡∏à‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏°‡∏õ‡∏è‡∏¥‡∏£‡∏π‡∏õ‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡∏†‡∏≤‡∏Ñ‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏è‡∏¥‡∏£‡∏π‡∏õ‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏™‡∏±‡∏á‡∏Ñ‡∏° ‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏û‡∏±‡∏ô‡∏ò‡∏°‡∏¥‡∏ï‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ò‡∏¥‡∏õ‡πÑ‡∏ï‡∏¢ ‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ‡∏ô‡∏±‡πâ‡∏ô ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡πÑ‡∏î‡πâ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏à‡∏∞‡∏à‡∏∞‡∏à‡∏±‡∏î‡πÄ‡∏ß‡∏ó‡∏µ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏è‡∏¥‡∏£‡∏π‡∏õ‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 29 - 30 ‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô 2549 ‡πÇ‡∏î‡∏¢‡∏à‡∏∞‡πÄ‡∏ä‡∏¥‡∏ç‡πÄ‡∏à‡πâ‡∏≤‡∏Ç‡∏≠‡∏á‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡∏õ‡∏è‡∏¥‡∏£‡∏π‡∏õ‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏ù‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏°‡∏≤‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢\n",
      "Output: [('politics', 1.0), ('human_rights', 1.1085478490713285e-06), ('environment', 2.061147483800596e-07), ('national_security', 1.9711902154995187e-07), ('quality_of_life', 1.860524179164713e-07), ('culture', 1.5875950509780523e-07), ('international', 1.075283364571078e-07), ('economics', 6.568714638888196e-08), ('ict', 5.6130243564211924e-08), ('education', 5.2547459716834055e-08), ('social', 4.5213457866566387e-08), ('labor', 2.9078030649998254e-08)]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîÆ Manual Prediction Test:\")\n",
    "sample_text = \"‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡πÑ‡∏ó - ‡∏°‡∏ï‡∏¥‡∏û‡∏±‡∏ô‡∏ò‡∏°‡∏¥‡∏ï‡∏£‡∏Ø ‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ‡πÄ‡∏î‡∏¥‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏±‡∏î‡πÄ‡∏ß‡∏ó‡∏µ‡∏õ‡∏è‡∏¥‡∏£‡∏π‡∏õ‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á 29 - 30 ‡πÄ‡∏°‡∏©‡∏≤‡∏Ø ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏•‡∏∏‡∏¢‡∏ü‡πâ‡∏≠‡∏á‡∏®‡∏≤‡∏•‡∏õ‡∏Å‡∏Ñ‡∏£‡∏≠‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏¥‡∏Å‡∏ñ‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á 23 ‡πÄ‡∏°‡∏©‡∏≤‡∏Ø ‡∏ó‡∏ô‡∏≤‡∏¢‡∏ä‡∏µ‡πâ‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏≠‡∏∑‡πâ‡∏≠‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡πÉ‡∏´‡πâ‡πÑ‡∏ó‡∏¢‡∏£‡∏±‡∏Å‡πÑ‡∏ó‡∏¢‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏ß‡∏•‡∏≤ 10.30 ‡∏ô. ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 9 ‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô 2549 ‡∏ó‡∏µ‡πà‡∏´‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏Ñ‡∏ì‡∏∞‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ ‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡∏™‡∏á‡∏Ç‡∏•‡∏≤‡∏ô‡∏Ñ‡∏£‡∏¥‡∏ô‡∏ó‡∏£‡πå ‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡πÄ‡∏Ç‡∏ï‡∏´‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡πÅ‡∏Å‡∏ô‡∏ô‡∏≥‡∏û‡∏±‡∏ô‡∏ò‡∏°‡∏¥‡∏ï‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ò‡∏¥‡∏õ‡πÑ‡∏ï‡∏¢ ‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ ‡∏°‡∏µ‡∏ú‡∏π‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏° 30 ‡∏Ñ‡∏ô ‡πÇ‡∏î‡∏¢‡πÑ‡∏î‡πâ‡πÄ‡∏ä‡∏¥‡∏ç‡∏ô‡∏≤‡∏¢‡∏õ‡∏Å‡∏£‡∏ì‡πå ‡∏£‡∏≠‡∏á‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏¥‡πå ‡∏õ‡∏£‡∏∞‡∏ò‡∏≤‡∏ô‡∏™‡∏†‡∏≤‡∏ó‡∏ô‡∏≤‡∏¢‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏™‡∏á‡∏Ç‡∏•‡∏≤ ‡∏°‡∏≤‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏≤‡∏á‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á ‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 23 ‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô 2549‡∏ô‡∏≤‡∏¢‡∏õ‡∏Å‡∏£‡∏ì‡πå ‡∏Å‡∏•‡πà‡∏≤‡∏ß‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡∏ß‡πà‡∏≤ ‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ì‡∏∞‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á (‡∏Å‡∏Å‡∏ï.) ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏£‡∏±‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏™‡∏†‡∏≤‡∏ú‡∏π‡πâ‡πÅ‡∏ó‡∏ô‡∏£‡∏≤‡∏©‡∏é‡∏£‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 2 ‡πÉ‡∏ô‡πÄ‡∏Ç‡∏ï‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡πÑ‡∏î‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÑ‡∏°‡πà‡∏ñ‡∏∂‡∏á‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ 20 ‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏≠‡∏∑‡πâ‡∏≠‡πÉ‡∏´‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏£‡∏£‡∏Ñ‡πÑ‡∏ó‡∏¢‡∏£‡∏±‡∏Å‡πÑ‡∏ó‡∏¢ ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ú‡∏¥‡∏î‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏£‡∏±‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏£‡∏±‡∏ö‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏£‡∏±‡∏ê‡∏ò‡∏£‡∏£‡∏°‡∏ô‡∏π‡∏ç‡∏ß‡πà‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏™‡∏†‡∏≤‡∏ú‡∏π‡πâ‡πÅ‡∏ó‡∏ô‡∏£‡∏≤‡∏©‡∏é‡∏£‡πÅ‡∏•‡∏∞‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏ß‡∏∏‡∏í‡∏¥‡∏™‡∏†‡∏≤ ‡∏°‡∏≤‡∏ï‡∏£‡∏≤ 74(2) ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏´‡∏°‡πà ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏£‡∏±‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏´‡∏°‡πà ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á‡∏Å‡πá‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏û‡∏£‡∏£‡∏Ñ‡πÑ‡∏ó‡∏¢‡∏£‡∏±‡∏Å‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç 2 ‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å‡∏à‡∏∂‡∏á‡πÑ‡∏î‡πâ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÑ‡∏î‡πâ‡∏´‡∏≤‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡∏ô‡∏≤‡∏¢‡∏õ‡∏Å‡∏£‡∏ì‡πå ‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏≠‡∏µ‡∏Å‡∏ß‡πà‡∏≤ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô ‡∏ï‡∏≤‡∏°‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏ö‡∏±‡∏ç‡∏ç‡∏±‡∏ï‡∏¥‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏£‡∏±‡∏ê‡∏ò‡∏£‡∏£‡∏°‡∏ô‡∏π‡∏ç‡∏ß‡πà‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ì‡∏∞‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á ‡∏°‡∏≤‡∏ï‡∏£‡∏≤ 24 ‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤ ‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏¥‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á ‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏ô‡πÄ‡∏Ç‡∏ï‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á ‡πÅ‡∏•‡∏∞‡∏≠‡∏ô‡∏∏‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á ‡∏Å‡∏£‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏ô‡∏°‡∏¥‡∏ä‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏´‡πâ‡πÇ‡∏ó‡∏©‡πÅ‡∏Å‡πà‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏£‡∏£‡∏Ñ‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á ‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏´‡∏£‡∏∑‡∏≠‡∏•‡∏∞‡πÄ‡∏ß‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡πÇ‡∏î‡∏¢‡∏°‡∏¥‡∏ä‡∏≠‡∏ö ‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡∏á‡πÇ‡∏ó‡∏©‡∏ô‡∏±‡πâ‡∏ô‡∏ï‡∏≤‡∏°‡∏°‡∏≤‡∏ï‡∏£‡∏≤ 29 ‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤ ‡πÉ‡∏´‡πâ‡∏à‡∏≥‡∏Ñ‡∏∏‡∏Å 1 -10 ‡∏õ‡∏µ ‡∏õ‡∏£‡∏±‡∏ö 20,000 - 200,000 ‡∏ö‡∏≤‡∏ó ‡πÅ‡∏•‡∏∞‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏®‡∏≤‡∏•‡πÄ‡∏û‡∏¥‡∏Å‡∏ñ‡∏≠‡∏ô‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏•‡∏≤ 10 ‡∏õ‡∏µ ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡∏à‡∏∂‡∏á‡∏•‡∏á‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏ü‡πâ‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Ñ‡∏î‡∏µ‡∏õ‡∏Å‡∏Ñ‡∏£‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ì‡∏∞‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á ‡πÇ‡∏î‡∏¢‡∏à‡∏∞‡∏ü‡πâ‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡∏ï‡πà‡∏≠‡∏®‡∏≤‡∏•‡∏õ‡∏Å‡∏Ñ‡∏£‡∏≠‡∏á‡∏™‡∏á‡∏Ç‡∏•‡∏≤ ‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏®‡∏≤‡∏•‡∏õ‡∏Å‡∏Ñ‡∏£‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÄ‡∏û‡∏¥‡∏Å‡∏ñ‡∏≠‡∏ô‡∏°‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ì‡∏∞‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡∏¥‡∏î‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏£‡∏±‡∏ö‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 23 ‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô 2549 ‡πÅ‡∏•‡∏∞‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏¢‡∏±‡∏ö‡∏¢‡∏±‡πâ‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏î‡∏±‡∏á‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏î‡πâ‡∏ß‡∏¢‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡∏¢‡∏±‡∏á‡∏°‡∏µ‡∏°‡∏ï‡∏¥‡∏à‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏°‡∏õ‡∏è‡∏¥‡∏£‡∏π‡∏õ‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡∏†‡∏≤‡∏Ñ‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏è‡∏¥‡∏£‡∏π‡∏õ‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏™‡∏±‡∏á‡∏Ñ‡∏° ‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏û‡∏±‡∏ô‡∏ò‡∏°‡∏¥‡∏ï‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ò‡∏¥‡∏õ‡πÑ‡∏ï‡∏¢ ‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ‡∏ô‡∏±‡πâ‡∏ô ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡πÑ‡∏î‡πâ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏à‡∏∞‡∏à‡∏∞‡∏à‡∏±‡∏î‡πÄ‡∏ß‡∏ó‡∏µ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏è‡∏¥‡∏£‡∏π‡∏õ‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 29 - 30 ‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô 2549 ‡πÇ‡∏î‡∏¢‡∏à‡∏∞‡πÄ‡∏ä‡∏¥‡∏ç‡πÄ‡∏à‡πâ‡∏≤‡∏Ç‡∏≠‡∏á‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡∏õ‡∏è‡∏¥‡∏£‡∏π‡∏õ‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏ù‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏°‡∏≤‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢\"\n",
    "print(f\"Input: {sample_text}\")\n",
    "print(f\"Output: {predict(sample_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d6dc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÆ Manual Prediction Test:\n",
      "Input: ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 1 ‡∏Å.‡∏¢.‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤ ‡∏ú‡∏π‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå [1] ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ß‡πà‡∏≤¬†‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏®‡∏≤‡∏•‡∏¢‡∏∏‡∏ï‡∏¥‡∏ò‡∏£‡∏£‡∏° ‡∏ñ‡∏ô‡∏ô‡∏£‡∏±‡∏ä‡∏î‡∏≤‡∏†‡∏¥‡πÄ‡∏©‡∏Å ‡πÄ‡∏ß‡∏•‡∏≤ 13.00 ‡∏ô. 1 ‡∏Å.‡∏¢.59 ‡∏û‡∏•.‡∏ï.‡∏ô‡∏û.‡πÄ‡∏´‡∏£‡∏µ‡∏¢‡∏ç‡∏ó‡∏≠‡∏á ‡πÅ‡∏ô‡πà‡∏ô‡∏´‡∏ô‡∏≤ ‡∏ú‡∏≠.‡∏£‡∏û.‡∏°‡∏á‡∏Å‡∏∏‡∏é‡∏ß‡∏±‡∏í‡∏ô‡∏∞ ‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡∏ô‡∏ô‡∏≥‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡∏¢‡∏∞‡πÅ‡∏ú‡πà‡∏ô‡∏î‡∏¥‡∏ô ‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á‡∏°‡∏≤‡∏¢‡∏∑‡πà‡∏ô‡∏Ñ‡∏≥‡∏£‡πâ‡∏≠‡∏á‡∏ñ‡∏∂‡∏á‡πÄ‡∏•‡∏Ç‡∏≤‡∏ò‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏®‡∏≤‡∏•‡∏¢‡∏∏‡∏ï‡∏¥‡∏ò‡∏£‡∏£‡∏° ‡∏Ñ‡∏±‡∏î‡∏Ñ‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏™‡∏ô‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏õ‡∏£‡∏î‡πÄ‡∏Å‡∏•‡πâ‡∏≤‡∏Ø ‡πÅ‡∏ï‡πà‡∏á‡∏ï‡∏±‡πâ‡∏á‡∏ú‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏ö‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏±‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ú‡∏π‡πâ‡∏û‡∏¥‡∏û‡∏≤‡∏Å‡∏©‡∏≤‡∏£‡∏≤‡∏¢‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡πÇ‡∏î‡∏¢ ‡∏û‡∏•.‡∏ï.‡∏ô‡∏û.‡πÄ‡∏´‡∏£‡∏µ‡∏¢‡∏ç‡∏ó‡∏≠‡∏á ‡∏ú‡∏≠.‡∏£‡∏û.‡∏°‡∏á‡∏Å‡∏∏‡∏é‡∏ß‡∏±‡∏í‡∏ô‡∏∞ ‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ß‡πà‡∏≤ ‡∏Å‡∏≤‡∏£‡∏¢‡∏∑‡πà‡∏ô‡∏Ñ‡∏±‡∏î‡∏Ñ‡πâ‡∏≤‡∏ô‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô ‡∏°‡∏¥.‡∏¢.‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤ ‡πÑ‡∏î‡πâ‡∏û‡∏ö‡πÄ‡∏´‡πá‡∏ô‡πÄ‡∏û‡∏à‡πÄ‡∏ü‡∏ã‡∏ö‡∏∏‡πä‡∏Å‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏ö‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏±‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ú‡∏π‡πâ‡∏û‡∏¥‡∏û‡∏≤‡∏Å‡∏©‡∏≤‡∏£‡∏≤‡∏¢‡∏ô‡∏µ‡πâ‡∏Å‡∏î‡∏ñ‡∏π‡∏Å‡πÉ‡∏à‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏´‡∏°‡∏¥‡πà‡∏ô‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏Ø ‡∏ã‡∏∂‡πà‡∏á‡∏ï‡∏ô‡πÑ‡∏î‡πâ‡∏ô‡∏≥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ä‡∏µ‡πâ‡πÅ‡∏à‡∏á‡πÉ‡∏´‡πâ ‡∏õ.‡∏õ.‡∏ä.‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô‡∏ï‡πâ‡∏ô‡∏™‡∏±‡∏á‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏á‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏ô‡∏±‡πâ‡∏ô‡∏ó‡∏£‡∏≤‡∏ö‡∏î‡πâ‡∏ß‡∏¢ ‡πÅ‡∏ï‡πà‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏î‡∏±‡∏á‡∏Å‡∏•‡πà‡∏≤‡∏ß‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏•‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏õ‡∏¥‡∏î‡πÄ‡∏û‡∏à‡πÄ‡∏ü‡∏ã‡∏ö‡∏∏‡πä‡∏Å‡∏ô‡∏±‡πâ‡∏ô ‡πÅ‡∏ï‡πà‡∏ï‡∏ô‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏ó‡∏≥‡∏ô‡∏±‡πâ‡∏ô‡πÑ‡∏ß‡πâ‡πÑ‡∏î‡πâ‡∏ó‡∏±‡∏ô‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏∂‡∏á‡∏ô‡∏≥‡∏°‡∏≤‡∏¢‡∏∑‡πà‡∏ô‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏Ç‡∏≤‡∏ò‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏®‡∏≤‡∏•‡∏¢‡∏∏‡∏ï‡∏¥‡∏ò‡∏£‡∏£‡∏°‡πÑ‡∏ß‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡∏Ñ‡∏ì‡∏∞‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏∏‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡∏®‡∏≤‡∏•‡∏¢‡∏∏‡∏ï‡∏¥‡∏ò‡∏£‡∏£‡∏° (‡∏Å.‡∏ï.) ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏ï‡∏≤‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ï‡∏ô‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡∏ú‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ó‡∏±‡∏®‡∏ô‡∏Ñ‡∏ï‡∏¥‡∏´‡∏°‡∏¥‡πà‡∏ô‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏Ø ‡∏à‡∏∞‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏û‡∏¥‡∏û‡∏≤‡∏Å‡∏©‡∏≤‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£\n",
      "Output: [('politics', 0.9999704360961914), ('ict', 0.036877721548080444), ('culture', 2.303324617969338e-05), ('environment', 2.0398518245201558e-05), ('economics', 1.8042044757748954e-05), ('human_rights', 1.7615016986383125e-05), ('education', 1.4205607840267476e-05), ('national_security', 9.79614196694456e-06), ('international', 7.094598913681693e-06), ('labor', 1.9023083268621122e-06), ('quality_of_life', 1.7941282521860558e-06), ('social', 1.1082296396125457e-06)]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîÆ Manual Prediction Test:\")\n",
    "sample_text = \"‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 1 ‡∏Å.‡∏¢.‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤ ‡∏ú‡∏π‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå [1] ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ß‡πà‡∏≤¬†‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏®‡∏≤‡∏•‡∏¢‡∏∏‡∏ï‡∏¥‡∏ò‡∏£‡∏£‡∏° ‡∏ñ‡∏ô‡∏ô‡∏£‡∏±‡∏ä‡∏î‡∏≤‡∏†‡∏¥‡πÄ‡∏©‡∏Å ‡πÄ‡∏ß‡∏•‡∏≤ 13.00 ‡∏ô. 1 ‡∏Å.‡∏¢.59 ‡∏û‡∏•.‡∏ï.‡∏ô‡∏û.‡πÄ‡∏´‡∏£‡∏µ‡∏¢‡∏ç‡∏ó‡∏≠‡∏á ‡πÅ‡∏ô‡πà‡∏ô‡∏´‡∏ô‡∏≤ ‡∏ú‡∏≠.‡∏£‡∏û.‡∏°‡∏á‡∏Å‡∏∏‡∏é‡∏ß‡∏±‡∏í‡∏ô‡∏∞ ‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡∏ô‡∏ô‡∏≥‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡∏¢‡∏∞‡πÅ‡∏ú‡πà‡∏ô‡∏î‡∏¥‡∏ô ‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á‡∏°‡∏≤‡∏¢‡∏∑‡πà‡∏ô‡∏Ñ‡∏≥‡∏£‡πâ‡∏≠‡∏á‡∏ñ‡∏∂‡∏á‡πÄ‡∏•‡∏Ç‡∏≤‡∏ò‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏®‡∏≤‡∏•‡∏¢‡∏∏‡∏ï‡∏¥‡∏ò‡∏£‡∏£‡∏° ‡∏Ñ‡∏±‡∏î‡∏Ñ‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏™‡∏ô‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏õ‡∏£‡∏î‡πÄ‡∏Å‡∏•‡πâ‡∏≤‡∏Ø ‡πÅ‡∏ï‡πà‡∏á‡∏ï‡∏±‡πâ‡∏á‡∏ú‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏ö‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏±‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ú‡∏π‡πâ‡∏û‡∏¥‡∏û‡∏≤‡∏Å‡∏©‡∏≤‡∏£‡∏≤‡∏¢‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡πÇ‡∏î‡∏¢ ‡∏û‡∏•.‡∏ï.‡∏ô‡∏û.‡πÄ‡∏´‡∏£‡∏µ‡∏¢‡∏ç‡∏ó‡∏≠‡∏á ‡∏ú‡∏≠.‡∏£‡∏û.‡∏°‡∏á‡∏Å‡∏∏‡∏é‡∏ß‡∏±‡∏í‡∏ô‡∏∞ ‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ß‡πà‡∏≤ ‡∏Å‡∏≤‡∏£‡∏¢‡∏∑‡πà‡∏ô‡∏Ñ‡∏±‡∏î‡∏Ñ‡πâ‡∏≤‡∏ô‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô ‡∏°‡∏¥.‡∏¢.‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤ ‡πÑ‡∏î‡πâ‡∏û‡∏ö‡πÄ‡∏´‡πá‡∏ô‡πÄ‡∏û‡∏à‡πÄ‡∏ü‡∏ã‡∏ö‡∏∏‡πä‡∏Å‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏ö‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏±‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ú‡∏π‡πâ‡∏û‡∏¥‡∏û‡∏≤‡∏Å‡∏©‡∏≤‡∏£‡∏≤‡∏¢‡∏ô‡∏µ‡πâ‡∏Å‡∏î‡∏ñ‡∏π‡∏Å‡πÉ‡∏à‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏´‡∏°‡∏¥‡πà‡∏ô‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏Ø ‡∏ã‡∏∂‡πà‡∏á‡∏ï‡∏ô‡πÑ‡∏î‡πâ‡∏ô‡∏≥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ä‡∏µ‡πâ‡πÅ‡∏à‡∏á‡πÉ‡∏´‡πâ ‡∏õ.‡∏õ.‡∏ä.‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô‡∏ï‡πâ‡∏ô‡∏™‡∏±‡∏á‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏á‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏ô‡∏±‡πâ‡∏ô‡∏ó‡∏£‡∏≤‡∏ö‡∏î‡πâ‡∏ß‡∏¢ ‡πÅ‡∏ï‡πà‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏î‡∏±‡∏á‡∏Å‡∏•‡πà‡∏≤‡∏ß‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏•‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏õ‡∏¥‡∏î‡πÄ‡∏û‡∏à‡πÄ‡∏ü‡∏ã‡∏ö‡∏∏‡πä‡∏Å‡∏ô‡∏±‡πâ‡∏ô ‡πÅ‡∏ï‡πà‡∏ï‡∏ô‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏ó‡∏≥‡∏ô‡∏±‡πâ‡∏ô‡πÑ‡∏ß‡πâ‡πÑ‡∏î‡πâ‡∏ó‡∏±‡∏ô‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏∂‡∏á‡∏ô‡∏≥‡∏°‡∏≤‡∏¢‡∏∑‡πà‡∏ô‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏Ç‡∏≤‡∏ò‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏®‡∏≤‡∏•‡∏¢‡∏∏‡∏ï‡∏¥‡∏ò‡∏£‡∏£‡∏°‡πÑ‡∏ß‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡∏Ñ‡∏ì‡∏∞‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏∏‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡∏®‡∏≤‡∏•‡∏¢‡∏∏‡∏ï‡∏¥‡∏ò‡∏£‡∏£‡∏° (‡∏Å.‡∏ï.) ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏ï‡∏≤‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ï‡∏ô‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡∏ú‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ó‡∏±‡∏®‡∏ô‡∏Ñ‡∏ï‡∏¥‡∏´‡∏°‡∏¥‡πà‡∏ô‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏Ø ‡∏à‡∏∞‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏û‡∏¥‡∏û‡∏≤‡∏Å‡∏©‡∏≤‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£\"\n",
    "print(f\"Input: {sample_text}\")\n",
    "print(f\"Output: {predict(sample_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "663aa6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÆ Manual Prediction Test:\n",
      "Input: 17 ‡∏û.‡∏¢. 2558 Blognone [1] ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ß‡πà‡∏≤ ‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÅ‡∏Æ‡∏Ñ‡πÄ‡∏Å‡∏≠‡∏£‡πå Anonymous ‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°‡πÑ‡∏ã‡πÄ‡∏ö‡∏≠‡∏£‡πå‡∏Å‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏´‡∏±‡∏ß‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡∏∏‡πà‡∏° IS ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ‡∏Å‡∏£‡∏∏‡∏á‡∏õ‡∏≤‡∏£‡∏µ‡∏™‡πÉ‡∏ô‡∏Ñ‡∏∑‡∏ô‡∏ß‡∏±‡∏ô‡∏®‡∏∏‡∏Å‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤ ‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡πÉ‡∏ô YouTube ‡πÇ‡∏Ü‡∏©‡∏Å‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÅ‡∏Æ‡∏Ñ‡πÄ‡∏Å‡∏≠‡∏£‡πå‡∏™‡∏ß‡∏°‡∏´‡∏ô‡πâ‡∏≤‡∏Å‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÑ‡∏î‡πâ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏≠‡πà‡∏≤‡∏ô‡πÅ‡∏ñ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏ù‡∏£‡∏±‡πà‡∏á‡πÄ‡∏®‡∏™ ‡∏°‡∏µ‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡πà‡∏≤ ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏° IS ‡πÉ‡∏ô‡∏Å‡∏£‡∏∏‡∏á‡∏õ‡∏≤‡∏£‡∏µ‡∏™ ‡∏Å‡∏•‡∏∏‡πà‡∏° Anonymous ‡∏ó‡∏±‡πà‡∏ß‡πÇ‡∏•‡∏Å‡∏à‡∏∞‡∏ï‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏Å‡∏•‡∏∏‡πà‡∏° IS ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡∏ó‡∏≥‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏û‡∏¥‡∏°‡∏û‡πå Charlie Hebdo ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÉ‡∏´‡∏ç‡πà‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏° Anonymous ‡πÄ‡∏•‡∏¢ ‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ‡∏Å‡∏•‡∏∏‡πà‡∏° Anonymous ‡∏¢‡∏±‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à‡∏ï‡πà‡∏≠‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏£‡∏±‡∏ß‡∏ú‡∏π‡πâ‡∏™‡∏π‡∏ç‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏ô‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏µ‡πâ ‡∏Å‡∏•‡∏∏‡πà‡∏° Anonymous ‡πÄ‡∏Ñ‡∏¢‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°‡∏Å‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏° IS ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏û‡∏¥‡∏°‡∏û‡πå Charlie Hebdo ‡∏ó‡∏µ‡πà‡∏ù‡∏£‡∏±‡πà‡∏á‡πÄ‡∏®‡∏™‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡πâ‡∏ô‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤ ‡∏ã‡∏∂‡πà‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏±‡πâ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏° Anonymous ‡∏≠‡πâ‡∏≤‡∏á‡∏ß‡πà‡∏≤‡πÑ‡∏î‡πâ‡∏£‡∏∞‡∏á‡∏±‡∏ö‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö IS ‡πÑ‡∏õ‡∏´‡∏•‡∏≤‡∏¢‡∏û‡∏±‡∏ô‡∏ö‡∏±‡∏ç‡∏ä‡∏µ (‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡∏à‡∏≤‡∏ÅBlognone ‡∏ó‡∏µ‡πà‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÅ‡∏Æ‡∏Ñ‡πÄ‡∏Å‡∏≠‡∏£‡πå Anonymous ‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°‡πÑ‡∏ã‡πÄ‡∏ö‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏Å‡∏ß‡∏≤‡∏î‡∏•‡πâ‡∏≤‡∏á‡∏û‡∏ß‡∏Å ISIS [2])\n",
      "Output: [('international', 0.9998990297317505), ('ict', 0.06944242864847183), ('human_rights', 0.00045872002374380827), ('national_security', 0.000385454623028636), ('environment', 0.00029187160544097424), ('politics', 0.00015252380399033427), ('culture', 0.00010374216071795672), ('labor', 7.60196489864029e-05), ('economics', 7.433495193254203e-05), ('education', 5.6099568610079587e-05), ('quality_of_life', 3.213228046661243e-05), ('social', 1.951776721398346e-05)]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîÆ Manual Prediction Test:\")\n",
    "sample_text = \"17 ‡∏û.‡∏¢. 2558 Blognone [1] ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ß‡πà‡∏≤ ‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÅ‡∏Æ‡∏Ñ‡πÄ‡∏Å‡∏≠‡∏£‡πå Anonymous ‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°‡πÑ‡∏ã‡πÄ‡∏ö‡∏≠‡∏£‡πå‡∏Å‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏´‡∏±‡∏ß‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡∏∏‡πà‡∏° IS ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ‡∏Å‡∏£‡∏∏‡∏á‡∏õ‡∏≤‡∏£‡∏µ‡∏™‡πÉ‡∏ô‡∏Ñ‡∏∑‡∏ô‡∏ß‡∏±‡∏ô‡∏®‡∏∏‡∏Å‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤ ‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡πÉ‡∏ô YouTube ‡πÇ‡∏Ü‡∏©‡∏Å‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÅ‡∏Æ‡∏Ñ‡πÄ‡∏Å‡∏≠‡∏£‡πå‡∏™‡∏ß‡∏°‡∏´‡∏ô‡πâ‡∏≤‡∏Å‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÑ‡∏î‡πâ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏≠‡πà‡∏≤‡∏ô‡πÅ‡∏ñ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏ù‡∏£‡∏±‡πà‡∏á‡πÄ‡∏®‡∏™ ‡∏°‡∏µ‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡πà‡∏≤ ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏° IS ‡πÉ‡∏ô‡∏Å‡∏£‡∏∏‡∏á‡∏õ‡∏≤‡∏£‡∏µ‡∏™ ‡∏Å‡∏•‡∏∏‡πà‡∏° Anonymous ‡∏ó‡∏±‡πà‡∏ß‡πÇ‡∏•‡∏Å‡∏à‡∏∞‡∏ï‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏Å‡∏•‡∏∏‡πà‡∏° IS ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡∏ó‡∏≥‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏û‡∏¥‡∏°‡∏û‡πå Charlie Hebdo ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÉ‡∏´‡∏ç‡πà‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏° Anonymous ‡πÄ‡∏•‡∏¢ ‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ‡∏Å‡∏•‡∏∏‡πà‡∏° Anonymous ‡∏¢‡∏±‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à‡∏ï‡πà‡∏≠‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏£‡∏±‡∏ß‡∏ú‡∏π‡πâ‡∏™‡∏π‡∏ç‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏ô‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏µ‡πâ ‡∏Å‡∏•‡∏∏‡πà‡∏° Anonymous ‡πÄ‡∏Ñ‡∏¢‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°‡∏Å‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏° IS ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏û‡∏¥‡∏°‡∏û‡πå Charlie Hebdo ‡∏ó‡∏µ‡πà‡∏ù‡∏£‡∏±‡πà‡∏á‡πÄ‡∏®‡∏™‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡πâ‡∏ô‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤ ‡∏ã‡∏∂‡πà‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏±‡πâ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏° Anonymous ‡∏≠‡πâ‡∏≤‡∏á‡∏ß‡πà‡∏≤‡πÑ‡∏î‡πâ‡∏£‡∏∞‡∏á‡∏±‡∏ö‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö IS ‡πÑ‡∏õ‡∏´‡∏•‡∏≤‡∏¢‡∏û‡∏±‡∏ô‡∏ö‡∏±‡∏ç‡∏ä‡∏µ (‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡∏à‡∏≤‡∏ÅBlognone ‡∏ó‡∏µ‡πà‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÅ‡∏Æ‡∏Ñ‡πÄ‡∏Å‡∏≠‡∏£‡πå Anonymous ‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°‡πÑ‡∏ã‡πÄ‡∏ö‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏Å‡∏ß‡∏≤‡∏î‡∏•‡πâ‡∏≤‡∏á‡∏û‡∏ß‡∏Å ISIS [2])\"\n",
    "print(f\"Input: {sample_text}\")\n",
    "print(f\"Output: {predict(sample_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "705af318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÆ Manual Prediction Test:\n",
      "Input: ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ô‡∏±‡∏Å‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡πÑ‡∏ã‡πÄ‡∏ö‡∏≠‡∏£‡πå‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏Ñ‡∏±‡∏î‡∏Ñ‡πâ‡∏≤‡∏ô‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡∏Ñ‡∏á‡πÑ‡∏ã‡πÄ‡∏ö‡∏≠‡∏£‡πå‡∏â‡∏ö‡∏±‡∏ö‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡πÄ‡∏à‡πâ‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ê‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ä‡∏ó‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏´‡∏°‡∏≤‡∏¢‡∏®‡∏≤‡∏•‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏î‡πâ‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡∏Ñ‡∏á ‡πÅ‡∏ï‡πà‡∏†‡∏≤‡∏Ñ‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô‡∏°‡∏≠‡∏á‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡∏∞‡πÄ‡∏°‡∏¥‡∏î‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏£‡∏µ‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏≠‡∏≠‡∏Å‡∏ö‡∏ô‡πÇ‡∏•‡∏Å‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå\n",
      "Output: [('politics', 0.9563563466072083), ('social', 0.7164331078529358), ('national_security', 0.6731414794921875), ('culture', 0.41415703296661377), ('ict', 0.34446677565574646), ('human_rights', 0.29110872745513916), ('environment', 0.1756698489189148), ('quality_of_life', 0.08780661970376968), ('labor', 0.06037697568535805), ('economics', 0.05850338190793991), ('international', 0.047269679605960846), ('education', 0.03665921092033386)]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîÆ Manual Prediction Test:\")\n",
    "sample_text = \"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ô‡∏±‡∏Å‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡πÑ‡∏ã‡πÄ‡∏ö‡∏≠‡∏£‡πå‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏Ñ‡∏±‡∏î‡∏Ñ‡πâ‡∏≤‡∏ô‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡∏Ñ‡∏á‡πÑ‡∏ã‡πÄ‡∏ö‡∏≠‡∏£‡πå‡∏â‡∏ö‡∏±‡∏ö‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡πÄ‡∏à‡πâ‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ê‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ä‡∏ó‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏´‡∏°‡∏≤‡∏¢‡∏®‡∏≤‡∏•‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏î‡πâ‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡∏Ñ‡∏á ‡πÅ‡∏ï‡πà‡∏†‡∏≤‡∏Ñ‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô‡∏°‡∏≠‡∏á‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡∏∞‡πÄ‡∏°‡∏¥‡∏î‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏£‡∏µ‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏≠‡∏≠‡∏Å‡∏ö‡∏ô‡πÇ‡∏•‡∏Å‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå\"\n",
    "print(f\"Input: {sample_text}\")\n",
    "print(f\"Output: {predict(sample_text)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
