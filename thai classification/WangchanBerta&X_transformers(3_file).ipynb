{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install x-transformers"
      ],
      "metadata": {
        "id": "94kIwVrAtcr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYM43VN2tIB3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from x_transformers import TransformerWrapper, Decoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_CSV = \"prachatai_train.csv\"\n",
        "VAL_CSV   = \"prachatai_val.csv\"\n",
        "TEST_CSV  = \"prachatai_test.csv\"\n",
        "\n",
        "MODEL_PATH = \"wangchan_xt_best.pt\"\n",
        "\n",
        "MAX_LEN = 256\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 40\n",
        "PATIENCE = 8\n",
        "LR = 2e-4"
      ],
      "metadata": {
        "id": "ZBOHRCrjtY3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL_COLS = [\n",
        "    \"politics\", \"human_rights\", \"quality_of_life\", \"international\",\n",
        "    \"social\", \"environment\", \"economics\", \"culture\", \"labor\",\n",
        "    \"national_security\", \"ict\", \"education\"\n",
        "]"
      ],
      "metadata": {
        "id": "bFwI4MgEtimw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"airesearch/wangchanberta-base-att-spm-uncased\"\n",
        ")\n",
        "PAD_ID = tokenizer.pad_token_id"
      ],
      "metadata": {
        "id": "V7TricdItifD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(csv_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    texts = df[\"body_text\"].astype(str).tolist()\n",
        "    labels = df[LABEL_COLS].values.astype(np.float32)\n",
        "\n",
        "    enc = tokenizer(\n",
        "        texts,\n",
        "        truncation=True,\n",
        "        max_length=MAX_LEN,\n",
        "        padding=False\n",
        "    )\n",
        "    return enc[\"input_ids\"], labels\n",
        "\n",
        "X_train, y_train = load_dataset(TRAIN_CSV)\n",
        "X_val, y_val     = load_dataset(VAL_CSV)\n",
        "X_test, y_test   = load_dataset(TEST_CSV)"
      ],
      "metadata": {
        "id": "bgMFRc2Gtia4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ThaiDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.X[idx]), self.y[idx]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    seqs, labels = zip(*batch)\n",
        "\n",
        "    padded = pad_sequence(\n",
        "        seqs, batch_first=True, padding_value=PAD_ID\n",
        "    )\n",
        "    attn_mask = (padded != PAD_ID).long()\n",
        "\n",
        "    return (\n",
        "        padded.to(device),\n",
        "        attn_mask.to(device),\n",
        "        torch.stack(labels).to(device)\n",
        "    )\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    ThaiDataset(X_train, y_train),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    ThaiDataset(X_val, y_val),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    ThaiDataset(X_test, y_test),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ],
      "metadata": {
        "id": "QckrFAwYthzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = AutoModel.from_pretrained(\n",
        "    \"airesearch/wangchanberta-base-att-spm-uncased\"\n",
        ")\n",
        "for p in encoder.parameters():\n",
        "    p.requires_grad = False"
      ],
      "metadata": {
        "id": "nReb2uh4tqtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WangchanXTClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.hidden = encoder.config.hidden_size  # 768\n",
        "\n",
        "        self.decoder = TransformerWrapper(\n",
        "            num_tokens=1,          # dummy\n",
        "            max_seq_len=MAX_LEN,\n",
        "            attn_layers=Decoder(\n",
        "                dim=self.hidden,\n",
        "                depth=3,\n",
        "                heads=8,\n",
        "                cross_attend=True,\n",
        "                causal=False\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Linear(self.hidden, len(LABEL_COLS))\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # ----- Encoder -----\n",
        "        enc = self.encoder(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        ).last_hidden_state            # [B, L, 768]\n",
        "\n",
        "        # ----- Decoder -----\n",
        "        dummy = torch.zeros(\n",
        "            enc.size(0),\n",
        "            enc.size(1),\n",
        "            self.hidden,\n",
        "            device=enc.device\n",
        "        )\n",
        "\n",
        "        dec = self.decoder(\n",
        "            x=dummy,\n",
        "            context=enc,\n",
        "            context_mask=attention_mask.bool(),\n",
        "            return_embeddings=True\n",
        "        )\n",
        "\n",
        "        mask = attention_mask.unsqueeze(-1)\n",
        "        pooled = (dec * mask).sum(1) / mask.sum(1).clamp(min=1)\n",
        "\n",
        "        return torch.sigmoid(self.classifier(pooled))"
      ],
      "metadata": {
        "id": "IO5k4MP09Bbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = WangchanXTClassifier().to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.AdamW(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=LR\n",
        ")\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ],
      "metadata": {
        "id": "Vm863WFAtqqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience):\n",
        "        self.best = 0.0\n",
        "        self.counter = 0\n",
        "        self.patience = patience\n",
        "\n",
        "    def step(self, score, model):\n",
        "        if score > self.best:\n",
        "            self.best = score\n",
        "            self.counter = 0\n",
        "            torch.save(model.state_dict(), MODEL_PATH)\n",
        "            return False\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            return self.counter >= self.patience\n"
      ],
      "metadata": {
        "id": "5sj9SHZBtqna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(PATIENCE)\n",
        "\n",
        "# ---------------- TRAIN ----------------\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for Xb, maskb, yb in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            preds = model(Xb, maskb)\n",
        "            loss = criterion(preds, yb)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # ----- VALIDATION -----\n",
        "    model.eval()\n",
        "    yt, yp = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for Xb, maskb, yb in val_loader:\n",
        "            preds = (model(Xb, maskb) > 0.5).int()\n",
        "            yt.append(yb.cpu().numpy())\n",
        "            yp.append(preds.cpu().numpy())\n",
        "\n",
        "    yt = np.vstack(yt)\n",
        "    yp = np.vstack(yp)\n",
        "    val_f1 = f1_score(yt, yp, average=\"macro\")\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch+1:03d} | \"\n",
        "        f\"Loss {total_loss:.4f} | \"\n",
        "        f\"Val F1 {val_f1:.4f}\"\n",
        "    )\n",
        "\n",
        "    if early_stop.step(val_f1, model):\n",
        "        print(\"⏹ Early stopping\")\n",
        "        break"
      ],
      "metadata": {
        "id": "EzY7-x5Ht7yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(MODEL_PATH))\n",
        "model.eval()\n",
        "\n",
        "yt, yp = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for Xb, maskb, yb in test_loader:\n",
        "        preds = (model(Xb, maskb) > 0.5).int()\n",
        "        yt.append(yb.cpu().numpy())\n",
        "        yp.append(preds.cpu().numpy())\n",
        "\n",
        "yt = np.vstack(yt)\n",
        "yp = np.vstack(yp)\n",
        "\n",
        "print(\"\\nFINAL TEST RESULTS\")\n",
        "print(\"Macro F1:\", f1_score(yt, yp, average=\"macro\"))\n",
        "print(\"Micro F1:\", f1_score(yt, yp, average=\"micro\"))\n",
        "\n",
        "for i, label in enumerate(LABEL_COLS):\n",
        "    print(label, f1_score(yt[:, i], yp[:, i]))"
      ],
      "metadata": {
        "id": "jjTZXc_7t7u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text, threshold=0.5):\n",
        "    enc = tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        max_length=MAX_LEN,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        probs = model(\n",
        "            enc[\"input_ids\"].to(device),\n",
        "            enc[\"attention_mask\"].to(device)\n",
        "        )[0].cpu().numpy()\n",
        "\n",
        "    return sorted(\n",
        "        [(LABEL_COLS[i], float(probs[i]))\n",
        "         for i in range(len(LABEL_COLS)) if probs[i] >= threshold],\n",
        "        key=lambda x: x[1],\n",
        "        reverse=True\n",
        "    )\n",
        "\n",
        "print(\"\\nPREDICT EXAMPLES\")\n",
        "print(predict(\"รัฐบาลไทยประกาศนโยบายด้านสิ่งแวดล้อมใหม่\"))\n",
        "print(predict(\"แรงงานเรียกร้องสิทธิ์การทำงาน\"))"
      ],
      "metadata": {
        "id": "KPi-cyuBuF7w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}