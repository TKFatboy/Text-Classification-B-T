{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":14437544,"sourceType":"datasetVersion","datasetId":9221986}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":39469.399612,"end_time":"2026-01-14T00:03:02.840224","environment_variables":{},"exception":true,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2026-01-13T13:05:13.440612","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"593c32edbcb84f6d8fcfc23c8f1bf4d4":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60f99d14c798469faf6ee5e050138352":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_593c32edbcb84f6d8fcfc23c8f1bf4d4","placeholder":"‚Äã","style":"IPY_MODEL_693bddfc9c684f81ae59a87abb30a792","tabbable":null,"tooltip":null,"value":"‚Äá62452646/62452646‚Äá[00:00&lt;00:00,‚Äá109593084.23it/s]"}},"693bddfc9c684f81ae59a87abb30a792":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"8cc24a67cbf5446c9ea615c9800186cc":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac3125699fab451ba0cde90ef9e7a4d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_e7fc83b4d8464d10be9ed4e340ce2119","placeholder":"‚Äã","style":"IPY_MODEL_f1275793eb674e47b53b7a486375a331","tabbable":null,"tooltip":null,"value":"100%"}},"c08d17ac0c3b466baeaa01583614361a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_8cc24a67cbf5446c9ea615c9800186cc","max":62452646,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f7376ef1d0224df39ef3839ef47ab78e","tabbable":null,"tooltip":null,"value":62452646}},"df1aa3c01608484cbe2847999c5bbad2":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7fc83b4d8464d10be9ed4e340ce2119":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edefb592c0034f71b445ed4932728865":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ac3125699fab451ba0cde90ef9e7a4d8","IPY_MODEL_c08d17ac0c3b466baeaa01583614361a","IPY_MODEL_60f99d14c798469faf6ee5e050138352"],"layout":"IPY_MODEL_df1aa3c01608484cbe2847999c5bbad2","tabbable":null,"tooltip":null}},"f1275793eb674e47b53b7a486375a331":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"f7376ef1d0224df39ef3839ef47ab78e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üöÄ Thai Text Classification with Transformer\n### Encoder: thai2vec | Decoder: Transformer\n---\n**Settings:**\n- Train/Test/Valid = 80/10/10\n- MAX_LEN = 256\n- BATCH_SIZE = 128\n- EPOCHS = 500\n- dim = 300\n- depth = 4\n- heads = 4\n- LR = 2e-4\n- threshold = 0.5","metadata":{"papermill":{"duration":0.00351,"end_time":"2026-01-13T13:05:15.978692","exception":false,"start_time":"2026-01-13T13:05:15.975182","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# üì¶ Install dependencies\n!pip install -q transformers scikit-learn pythainlp pandas gensim x-transformers","metadata":{"execution":{"iopub.status.busy":"2026-01-14T05:27:23.353255Z","iopub.execute_input":"2026-01-14T05:27:23.353582Z","iopub.status.idle":"2026-01-14T05:27:26.845793Z","shell.execute_reply.started":"2026-01-14T05:27:23.353557Z","shell.execute_reply":"2026-01-14T05:27:26.844791Z"},"papermill":{"duration":6.208414,"end_time":"2026-01-13T13:05:22.189639","exception":false,"start_time":"2026-01-13T13:05:15.981225","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# üìö Import libraries\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda.amp import autocast, GradScaler\nfrom pythainlp import word_tokenize\nfrom pythainlp import word_vector\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom x_transformers import TransformerWrapper, Decoder\nimport time\nimport os\nfrom torch.amp import autocast, GradScaler","metadata":{"execution":{"iopub.status.busy":"2026-01-14T05:27:26.847774Z","iopub.execute_input":"2026-01-14T05:27:26.848050Z","iopub.status.idle":"2026-01-14T05:27:26.854308Z","shell.execute_reply.started":"2026-01-14T05:27:26.848027Z","shell.execute_reply":"2026-01-14T05:27:26.853479Z"},"papermill":{"duration":30.587789,"end_time":"2026-01-13T13:05:52.780391","exception":false,"start_time":"2026-01-13T13:05:22.192602","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ‚öôÔ∏è SETTINGS - ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î\nMAX_LEN = 256\nBATCH_SIZE = 128\nEPOCHS = 500\nLEARNING_RATE = 2e-4\nEMBED_DIM = 300  # dim=300\nDEPTH = 4\nHEADS = 4\nTHRESHOLD = 0.5\n\n# Split ratios\nTRAIN_RATIO = 0.80\nTEST_RATIO = 0.10\nVALID_RATIO = 0.10\n\nCHECKPOINT_EVERY = 10  # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å checkpoint ‡∏ó‡∏∏‡∏Å 10 epochs\n\nprint(\"‚úÖ Settings loaded:\")\nprint(f\"   MAX_LEN = {MAX_LEN}\")\nprint(f\"   BATCH_SIZE = {BATCH_SIZE}\")\nprint(f\"   EPOCHS = {EPOCHS}\")\nprint(f\"   LEARNING_RATE = {LEARNING_RATE}\")\nprint(f\"   EMBED_DIM = {EMBED_DIM}\")\nprint(f\"   DEPTH = {DEPTH}\")\nprint(f\"   HEADS = {HEADS}\")\nprint(f\"   THRESHOLD = {THRESHOLD}\")\nprint(f\"   Train/Valid/Test = {TRAIN_RATIO*100:.0f}%/{VALID_RATIO*100:.0f}%/{TEST_RATIO*100:.0f}%\")","metadata":{"execution":{"iopub.status.busy":"2026-01-14T05:27:26.855493Z","iopub.execute_input":"2026-01-14T05:27:26.856100Z","iopub.status.idle":"2026-01-14T05:27:26.870042Z","shell.execute_reply.started":"2026-01-14T05:27:26.856073Z","shell.execute_reply":"2026-01-14T05:27:26.869480Z"},"papermill":{"duration":0.011247,"end_time":"2026-01-13T13:05:52.794578","exception":false,"start_time":"2026-01-13T13:05:52.783331","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# üîß Check GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"üü¢ Using device: {device}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")","metadata":{"execution":{"iopub.status.busy":"2026-01-14T05:27:26.871029Z","iopub.execute_input":"2026-01-14T05:27:26.871297Z","iopub.status.idle":"2026-01-14T05:27:26.887202Z","shell.execute_reply.started":"2026-01-14T05:27:26.871269Z","shell.execute_reply":"2026-01-14T05:27:26.886644Z"},"papermill":{"duration":0.084315,"end_time":"2026-01-13T13:05:52.881716","exception":false,"start_time":"2026-01-13T13:05:52.797401","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# üìÇ Load Data\n# ‚ö†Ô∏è ‡πÅ‡∏Å‡πâ path ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£:\n# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Kaggle: \"/kaggle/input/prachatai-train/prachatai_train.csv\"\n# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Colab: \"prachatai_train.csv\" (upload ‡∏Å‡πà‡∏≠‡∏ô)\n# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Local: ‡πÉ‡∏™‡πà path ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á\n\nDATA_PATH = \"/kaggle/input/prachatai-train/prachatai_train.csv\"  # ‡πÅ‡∏Å‡πâ path ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n\nprint(f\"üìÇ Loading data from: {DATA_PATH}\")\ndf = pd.read_csv(DATA_PATH)\n\ntexts = df[\"body_text\"].astype(str).tolist()\nlabel_cols = [\n    \"politics\", \"human_rights\", \"quality_of_life\", \"international\",\n    \"social\", \"environment\", \"economics\", \"culture\", \"labor\",\n    \"national_security\", \"ict\", \"education\"\n]\ny = df[label_cols].values.astype(np.float32)\n\nprint(f\"üìä Dataset size: {len(texts)}\")\nprint(f\"üìã Labels: {label_cols}\")","metadata":{"execution":{"iopub.status.busy":"2026-01-14T05:27:26.889120Z","iopub.execute_input":"2026-01-14T05:27:26.889411Z","iopub.status.idle":"2026-01-14T05:27:37.590449Z","shell.execute_reply.started":"2026-01-14T05:27:26.889392Z","shell.execute_reply":"2026-01-14T05:27:37.589764Z"},"papermill":{"duration":13.61827,"end_time":"2026-01-13T13:06:06.502929","exception":false,"start_time":"2026-01-13T13:05:52.884659","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# üî§ Load thai2vec Word Embedding\nprint(\"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î thai2fit_wv...\")\nmodel_wv = word_vector.WordVector(model_name=\"thai2fit_wv\").get_model()\nw2v = model_wv\nembedding_dim = w2v.vector_size\n\n# ‡πÉ‡∏ä‡πâ dim ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î (‡∏ñ‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å thai2vec ‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á project)\nif embedding_dim != EMBED_DIM:\n    print(f\"‚ö†Ô∏è thai2vec dim ({embedding_dim}) != target dim ({EMBED_DIM})\")\n    print(f\"   ‡∏à‡∏∞‡πÉ‡∏ä‡πâ embedding_dim ‡∏à‡∏≤‡∏Å thai2vec = {embedding_dim}\")\nelse:\n    print(f\"‚úÖ Embedding dimension: {embedding_dim} (‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö dim ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î)\")\n\n# Tokenize\nprint(\"‡∏Å‡∏≥‡∏•‡∏±‡∏á tokenize...\")\ntokenized_texts = [word_tokenize(t, keep_whitespace=False) for t in texts]\n\n# Build vocabulary\nw2v_vocab = list(w2v.key_to_index.keys())\nvocab = {\"<PAD>\": 0, \"<UNK>\": 1}\nfor i, word in enumerate(w2v_vocab, start=2):\n    vocab[word] = i\n\nprint(f\"‚úÖ Vocab size: {len(vocab)}\")","metadata":{"execution":{"iopub.status.busy":"2026-01-14T05:27:37.591364Z","iopub.execute_input":"2026-01-14T05:27:37.591663Z","iopub.status.idle":"2026-01-14T05:41:05.314915Z","shell.execute_reply.started":"2026-01-14T05:27:37.591641Z","shell.execute_reply":"2026-01-14T05:41:05.314157Z"},"papermill":{"duration":769.092939,"end_time":"2026-01-13T13:18:55.598970","exception":false,"start_time":"2026-01-13T13:06:06.506031","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# üîß Encode & Pad\ndef encode_text(tokens, vocab):\n    return [vocab.get(w, vocab[\"<UNK>\"]) for w in tokens]\n\ndef pad_sequences(sequences, max_len=256, pad_value=0):\n    padded = np.full((len(sequences), max_len), pad_value, dtype=np.int64)\n    lengths = np.array([min(len(seq), max_len) for seq in sequences], dtype=np.int64)\n    for i, seq in enumerate(sequences):\n        padded[i, :min(len(seq), max_len)] = seq[:max_len]\n    return padded, lengths\n\nencoded_texts = [encode_text(tokens, vocab) for tokens in tokenized_texts]\nX, lengths = pad_sequences(encoded_texts, max_len=MAX_LEN)\n\nprint(f\"‚úÖ X shape: {X.shape}\")","metadata":{"execution":{"iopub.status.busy":"2026-01-14T05:41:05.315910Z","iopub.execute_input":"2026-01-14T05:41:05.316160Z","iopub.status.idle":"2026-01-14T05:41:17.084183Z","shell.execute_reply.started":"2026-01-14T05:41:05.316140Z","shell.execute_reply":"2026-01-14T05:41:17.083548Z"},"papermill":{"duration":13.288286,"end_time":"2026-01-13T13:19:08.890444","exception":false,"start_time":"2026-01-13T13:18:55.602158","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# üìä Train/Valid/Test Split (80/10/10)\nprint(f\"\\nüìä Splitting data: Train={TRAIN_RATIO*100:.0f}%, Valid={VALID_RATIO*100:.0f}%, Test={TEST_RATIO*100:.0f}%\")\n\n# ‡πÅ‡∏ö‡πà‡∏á train ‡πÅ‡∏•‡∏∞ temp (test+valid)\nX_train, X_temp, y_train, y_temp, len_train, len_temp = train_test_split(\n    X, y, lengths, \n    test_size=(TEST_RATIO + VALID_RATIO),  # 20%\n    random_state=42\n)\n\n# ‡πÅ‡∏ö‡πà‡∏á temp ‡πÄ‡∏õ‡πá‡∏ô test ‡πÅ‡∏•‡∏∞ valid (50/50 ‡∏Ç‡∏≠‡∏á 20% = 10% each)\nX_valid, X_test, y_valid, y_test, len_valid, len_test = train_test_split(\n    X_temp, y_temp, len_temp,\n    test_size=0.5,  # 50% ‡∏Ç‡∏≠‡∏á temp\n    random_state=42\n)\n\nprint(f\"‚úÖ Train size: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)\")\nprint(f\"‚úÖ Valid size: {len(X_valid)} ({len(X_valid)/len(X)*100:.1f}%)\")\nprint(f\"‚úÖ Test size: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)\")","metadata":{"execution":{"iopub.status.busy":"2026-01-14T05:41:17.085194Z","iopub.execute_input":"2026-01-14T05:41:17.085448Z","iopub.status.idle":"2026-01-14T05:41:17.152602Z","shell.execute_reply.started":"2026-01-14T05:41:17.085409Z","shell.execute_reply":"2026-01-14T05:41:17.151893Z"},"papermill":{"duration":0.070161,"end_time":"2026-01-13T13:19:08.963917","exception":false,"start_time":"2026-01-13T13:19:08.893756","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# üì¶ Dataset & DataLoader\nclass ThaiTextDataset(Dataset):\n    def __init__(self, X, lengths, y):\n        self.X = torch.tensor(X, dtype=torch.long)\n        self.lengths = torch.tensor(lengths, dtype=torch.long)\n        self.y = torch.tensor(y, dtype=torch.float32)\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return self.X[idx], self.lengths[idx], self.y[idx]\n\ntrain_dataset = ThaiTextDataset(X_train, len_train, y_train)\nvalid_dataset = ThaiTextDataset(X_valid, len_valid, y_valid)\ntest_dataset = ThaiTextDataset(X_test, len_test, y_test)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, \n                          num_workers=2, pin_memory=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE,\n                          num_workers=2, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, \n                         num_workers=2, pin_memory=True)\n\nprint(f\"‚úÖ Train batches per epoch: {len(train_loader)}\")\nprint(f\"‚úÖ Valid batches: {len(valid_loader)}\")\nprint(f\"‚úÖ Test batches: {len(test_loader)}\")","metadata":{"execution":{"iopub.status.busy":"2026-01-14T05:41:17.153578Z","iopub.execute_input":"2026-01-14T05:41:17.153858Z","iopub.status.idle":"2026-01-14T05:41:17.246325Z","shell.execute_reply.started":"2026-01-14T05:41:17.153827Z","shell.execute_reply":"2026-01-14T05:41:17.245468Z"},"papermill":{"duration":0.057519,"end_time":"2026-01-13T13:19:09.024842","exception":false,"start_time":"2026-01-13T13:19:08.967323","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# üß† Build Embedding Matrix\nvocab_size = max(vocab.values()) + 1\nembedding_matrix = np.zeros((vocab_size, embedding_dim))\n\nfor word, idx in vocab.items():\n    if word in w2v:\n        embedding_matrix[idx] = w2v[word]\n    elif word == \"<PAD>\":\n        embedding_matrix[idx] = np.zeros(embedding_dim)\n    else:\n        embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))\n\nprint(f\"‚úÖ Embedding matrix shape: {embedding_matrix.shape}\")","metadata":{"execution":{"iopub.status.busy":"2026-01-14T05:41:17.247446Z","iopub.execute_input":"2026-01-14T05:41:17.247742Z","iopub.status.idle":"2026-01-14T05:41:17.424615Z","shell.execute_reply.started":"2026-01-14T05:41:17.247722Z","shell.execute_reply":"2026-01-14T05:41:17.423959Z"},"papermill":{"duration":0.174339,"end_time":"2026-01-13T13:19:09.202689","exception":false,"start_time":"2026-01-13T13:19:09.028350","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ü§ñ Transformer Model\nclass TransformerClassifier(nn.Module):\n    def __init__(self, vocab_size, embed_dim, max_seq_len, output_dim, \n                 depth=4, heads=4, embedding_matrix=None):\n        super().__init__()\n        \n        self.transformer = TransformerWrapper(\n            num_tokens=vocab_size,\n            max_seq_len=max_seq_len,\n            attn_layers=Decoder(\n                dim=embed_dim,\n                depth=depth,\n                heads=heads,\n                attn_dropout=0.1,\n                ff_dropout=0.1\n            )\n        )\n        \n        if embedding_matrix is not None:\n            self.transformer.token_emb.emb.weight.data.copy_(\n                torch.tensor(embedding_matrix, dtype=torch.float32)\n            )\n        \n        self.fc1 = nn.Linear(embed_dim, embed_dim // 2)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.1)\n        self.fc2 = nn.Linear(embed_dim // 2, output_dim)\n\n    def forward(self, text, lengths=None):\n        transformer_out = self.transformer(text, return_embeddings=True)\n        \n        if lengths is not None:\n            mask = torch.arange(text.size(1), device=text.device).unsqueeze(0) < lengths.unsqueeze(1)\n            mask = mask.unsqueeze(-1).float()\n            pooled = (transformer_out * mask).sum(dim=1) / mask.sum(dim=1)\n        else:\n            pooled = transformer_out.mean(dim=1)\n        \n        out = self.fc1(pooled)\n        out = self.relu(out)\n        out = self.dropout(out)\n        out = self.fc2(out)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2026-01-14T05:41:17.425546Z","iopub.execute_input":"2026-01-14T05:41:17.425824Z","iopub.status.idle":"2026-01-14T05:41:17.433543Z","shell.execute_reply.started":"2026-01-14T05:41:17.425802Z","shell.execute_reply":"2026-01-14T05:41:17.432973Z"},"papermill":{"duration":0.066856,"end_time":"2026-01-13T13:19:09.273101","exception":false,"start_time":"2026-01-13T13:19:09.206245","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# üèóÔ∏è Create Model\noutput_dim = len(label_cols)\n\nmodel = TransformerClassifier(\n    vocab_size=len(vocab),\n    embed_dim=embedding_dim,  # ‡∏à‡∏≤‡∏Å thai2vec (300)\n    max_seq_len=MAX_LEN,\n    output_dim=output_dim,\n    depth=DEPTH,\n    heads=HEADS,\n    embedding_matrix=embedding_matrix\n).to(device)\n\nprint(f\"\\nü§ñ Model Configuration:\")\nprint(f\"   - vocab_size: {len(vocab)}\")\nprint(f\"   - embed_dim: {embedding_dim}\")\nprint(f\"   - max_seq_len: {MAX_LEN}\")\nprint(f\"   - depth: {DEPTH}\")\nprint(f\"   - heads: {HEADS}\")\nprint(f\"   - output_dim: {output_dim}\")\nprint(f\"‚úÖ Model parameters: {sum(p.numel() for p in model.parameters()):,}\")","metadata":{"execution":{"iopub.status.busy":"2026-01-14T05:41:17.434560Z","iopub.execute_input":"2026-01-14T05:41:17.434827Z","iopub.status.idle":"2026-01-14T05:41:18.048891Z","shell.execute_reply.started":"2026-01-14T05:41:17.434806Z","shell.execute_reply":"2026-01-14T05:41:18.048203Z"},"papermill":{"duration":0.58263,"end_time":"2026-01-13T13:19:09.859117","exception":false,"start_time":"2026-01-13T13:19:09.276487","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\n# üéØ Training with Mixed Precision & Validation\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\nscaler = GradScaler('cuda')  # üëà ‡πÅ‡∏Å‡πâ\n\nbest_val_loss = float('inf')\nbest_val_f1 = 0.0\nstart_epoch = 0\n\n# üìÇ Resume from checkpoint if exists\ncheckpoint_path = 'checkpoint.pth'\nif os.path.exists(checkpoint_path):\n    print(\"üìÇ Loading checkpoint...\")\n    checkpoint = torch.load(checkpoint_path)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n    start_epoch = checkpoint['epoch'] + 1\n    best_val_loss = checkpoint['best_val_loss']\n    print(f\"Resumed from epoch {start_epoch}\")\n\nprint(f\"\\nüöÄ Starting training from epoch {start_epoch + 1}...\")\nprint(f\"   Settings: BATCH_SIZE={BATCH_SIZE}, LR={LEARNING_RATE}, EPOCHS={EPOCHS}\")\nprint(f\"   Threshold: {THRESHOLD}\")\n\ntotal_start_time = time.time()\n\nfor epoch in range(start_epoch, EPOCHS):\n    epoch_start_time = time.time()\n    \n    # ========== Training ==========\n    model.train()\n    total_train_loss = 0\n    \n    for batch_idx, (X_batch, lengths_batch, y_batch) in enumerate(train_loader):\n        X_batch = X_batch.to(device)\n        lengths_batch = lengths_batch.to(device)\n        y_batch = y_batch.to(device)\n        \n        optimizer.zero_grad()\n        \n        # Mixed Precision Forward\n        with autocast('cuda'):  # üëà ‡πÅ‡∏Å‡πâ\n            outputs = model(X_batch, lengths_batch)\n            loss = criterion(outputs, y_batch)\n        \n        # Mixed Precision Backward\n        scaler.scale(loss).backward()\n        scaler.unscale_(optimizer)\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        scaler.step(optimizer)\n        scaler.update()\n        \n        total_train_loss += loss.item()\n    \n    avg_train_loss = total_train_loss / len(train_loader)\n    \n    # ========== Validation ==========\n    model.eval()\n    total_val_loss = 0\n    val_y_true, val_y_pred = [], []\n    \n    with torch.no_grad():\n        for X_batch, lengths_batch, y_batch in valid_loader:\n            X_batch, lengths_batch = X_batch.to(device), lengths_batch.to(device)\n            y_batch = y_batch.to(device)\n            \n            with autocast('cuda'):  # üëà ‡πÅ‡∏Å‡πâ\n                outputs = model(X_batch, lengths_batch)\n                loss = criterion(outputs, y_batch)\n            \n            total_val_loss += loss.item()\n            \n            preds = torch.sigmoid(outputs).cpu().numpy()\n            preds = (preds > THRESHOLD).astype(int)\n            val_y_true.append(y_batch.cpu().numpy())\n            val_y_pred.append(preds)\n    \n    avg_val_loss = total_val_loss / len(valid_loader)\n    val_y_true = np.vstack(val_y_true)\n    val_y_pred = np.vstack(val_y_pred)\n    val_f1 = f1_score(val_y_true, val_y_pred, average='macro')\n    \n    scheduler.step()\n    epoch_time = time.time() - epoch_start_time\n    \n    # Save best model\n    save_msg = \"\"\n    if avg_val_loss < best_val_loss:\n        best_val_loss = avg_val_loss\n        best_val_f1 = val_f1\n        torch.save(model.state_dict(), 'best_transformer_model.pth')\n        save_msg = \" üíæ\"\n    \n    # Save checkpoint\n    if (epoch + 1) % CHECKPOINT_EVERY == 0:\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'scheduler_state_dict': scheduler.state_dict(),\n            'best_val_loss': best_val_loss,\n        }, checkpoint_path)\n    \n    # Estimate remaining time\n    elapsed = time.time() - total_start_time\n    eta = (elapsed / (epoch - start_epoch + 1)) * (EPOCHS - epoch - 1) / 60\n    \n    print(f\"Epoch {epoch+1}/{EPOCHS} | Train: {avg_train_loss:.4f} | Val: {avg_val_loss:.4f} | F1: {val_f1:.4f} | {epoch_time:.1f}s | ETA: {eta:.0f}m{save_msg}\")\n\ntotal_time = time.time() - total_start_time\nprint(f\"\\n‚úÖ Training complete!\")\nprint(f\"üìä Best Val Loss: {best_val_loss:.4f} | Best F1: {best_val_f1:.4f}\")\nprint(f\"‚è±Ô∏è Total time: {total_time/3600:.2f} hours\")","metadata":{"execution":{"iopub.status.busy":"2026-01-14T05:41:18.049873Z","iopub.execute_input":"2026-01-14T05:41:18.050098Z","iopub.status.idle":"2026-01-14T05:41:19.637189Z","shell.execute_reply.started":"2026-01-14T05:41:18.050079Z","shell.execute_reply":"2026-01-14T05:41:19.636464Z"},"papermill":{"duration":38629.476564,"end_time":"2026-01-14T00:02:59.339309","exception":false,"start_time":"2026-01-13T13:19:09.862745","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# üìà Final Evaluation on Test Set\nprint(\"\\nüìà Evaluating on Test Set...\")\nmodel.load_state_dict(torch.load('best_transformer_model.pth'))\nmodel.eval()\n\ny_true, y_pred = [], []\nwith torch.no_grad():\n    for X_batch, lengths_batch, y_batch in test_loader:\n        X_batch, lengths_batch = X_batch.to(device), lengths_batch.to(device)\n        \n        with autocast('cuda'):\n            outputs = model(X_batch, lengths_batch)\n        \n        preds = torch.sigmoid(outputs).cpu().numpy()\n        preds = (preds > THRESHOLD).astype(int)\n        y_true.append(y_batch.numpy())\n        y_pred.append(preds)\n\ny_true = np.vstack(y_true)\ny_pred = np.vstack(y_pred)\n\nprint(f\"üìä Test F1-score (macro): {f1_score(y_true, y_pred, average='macro'):.4f}\")\nprint(f\"üìä Test F1-score (micro): {f1_score(y_true, y_pred, average='micro'):.4f}\")\nfor i, label in enumerate(label_cols):\n    print(label, f1_score(y_true[:, i], y_pred[:, i]))","metadata":{"execution":{"iopub.status.busy":"2026-01-14T05:55:43.570880Z","iopub.execute_input":"2026-01-14T05:55:43.571587Z","iopub.status.idle":"2026-01-14T05:55:47.042264Z","shell.execute_reply.started":"2026-01-14T05:55:43.571554Z","shell.execute_reply":"2026-01-14T05:55:47.041477Z"},"papermill":{"duration":0.440273,"end_time":"2026-01-14T00:02:59.799721","exception":true,"start_time":"2026-01-14T00:02:59.359448","status":"failed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# üîÆ Prediction Function\ndef predict(text):\n    model.eval()\n    tokens = word_tokenize(text, keep_whitespace=False)\n    ids = encode_text(tokens, vocab)[:MAX_LEN]\n    \n    # Pad\n    padded_ids = ids + [0] * (MAX_LEN - len(ids))\n    \n    lengths = torch.tensor([len(ids)], dtype=torch.long).to(device)\n    padded = torch.tensor([padded_ids], dtype=torch.long).to(device)\n    \n    with torch.no_grad():\n        with autocast('cuda'):\n            output = model(padded, lengths)\n        probs = torch.sigmoid(output).cpu().numpy()[0]\n        \n        # Multi-label results with threshold\n        results = [(label_cols[i], float(probs[i])) \n                   for i in range(len(probs)) if probs[i] > THRESHOLD]\n        \n        if not results:\n            best_idx = np.argmax(probs)\n            results = [(label_cols[best_idx], float(probs[best_idx]))]\n        \n        return results\n\n# Test predictions\nprint(\"\\nüîÆ Test Predictions:\")\nprint(predict(\"‡∏£‡∏±‡∏ê‡∏ö‡∏≤‡∏•‡πÑ‡∏ó‡∏¢‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢‡∏î‡πâ‡∏≤‡∏ô‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÉ‡∏´‡∏°‡πà\"))\nprint(predict(\"‡πÅ‡∏£‡∏á‡∏á‡∏≤‡∏ô‡∏õ‡∏£‡∏∞‡∏ó‡πâ‡∏ß‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô\"))","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T05:52:57.638576Z","iopub.execute_input":"2026-01-14T05:52:57.638880Z","iopub.status.idle":"2026-01-14T05:52:57.685473Z","shell.execute_reply.started":"2026-01-14T05:52:57.638856Z","shell.execute_reply":"2026-01-14T05:52:57.684810Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# üíæ Download model (for Colab)\n# from google.colab import files\n# files.download('best_transformer_model.pth')","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T05:41:19.652632Z","iopub.status.idle":"2026-01-14T05:41:19.652938Z","shell.execute_reply.started":"2026-01-14T05:41:19.652792Z","shell.execute_reply":"2026-01-14T05:41:19.652812Z"}},"outputs":[],"execution_count":null}]}